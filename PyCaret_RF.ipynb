{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4d87298-02ac-4f73-9141-822d3c4a55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e3301d9-a70c-4868-945f-9e493a403100",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe6567a7-57d6-4509-81a4-834804c8212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8688526 entries, 0 to 8688525\n",
      "Data columns (total 26 columns):\n",
      " #   Column     Dtype   \n",
      "---  ------     -----   \n",
      " 0   txkey      category\n",
      " 1   locdt      int32   \n",
      " 2   loctm      int32   \n",
      " 3   chid       category\n",
      " 4   cano       category\n",
      " 5   contp      category\n",
      " 6   etymd      category\n",
      " 7   mchno      category\n",
      " 8   acqic      category\n",
      " 9   mcc        category\n",
      " 10  conam      float32 \n",
      " 11  ecfg       category\n",
      " 12  insfg      category\n",
      " 13  iterm      float32 \n",
      " 14  bnsfg      category\n",
      " 15  flam1      int32   \n",
      " 16  stocn      category\n",
      " 17  scity      category\n",
      " 18  stscd      category\n",
      " 19  ovrlt      category\n",
      " 20  flbmk      category\n",
      " 21  hcefg      category\n",
      " 22  csmcu      category\n",
      " 23  csmam      int32   \n",
      " 24  flg_3dsmk  category\n",
      " 25  label      category\n",
      "dtypes: category(20), float32(2), int32(4)\n",
      "memory usage: 859.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_df[['txkey','chid','cano','contp','etymd','mchno','acqic','mcc','ecfg','insfg','bnsfg',\\\n",
    "          'stocn','scity','stscd','ovrlt','flbmk','hcefg','csmcu','flg_3dsmk','label']] = \\\n",
    "    train_df[['txkey','chid','cano','contp','etymd','mchno','acqic','mcc','ecfg','insfg','bnsfg','stocn',\\\n",
    "              'scity','stscd','ovrlt','flbmk','hcefg','csmcu','flg_3dsmk','label']].astype('category')\n",
    "\n",
    "train_df[train_df.select_dtypes(include='int64').columns] = \\\n",
    "    train_df[train_df.select_dtypes(include='int64').columns].astype('int32')\n",
    "\n",
    "train_df[train_df.select_dtypes(include='float64').columns] = \\\n",
    "    train_df[train_df.select_dtypes(include='float64').columns].astype('float32')\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf398560-daf1-4bed-9643-7306cc63cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txkey              0\n",
      "locdt              0\n",
      "loctm              0\n",
      "chid               0\n",
      "cano               0\n",
      "contp              0\n",
      "etymd         203455\n",
      "mchno              0\n",
      "acqic              0\n",
      "mcc             4550\n",
      "conam              0\n",
      "ecfg               0\n",
      "insfg              0\n",
      "iterm              0\n",
      "bnsfg              0\n",
      "flam1              0\n",
      "stocn            600\n",
      "scity         266066\n",
      "stscd        8665195\n",
      "ovrlt              0\n",
      "flbmk              0\n",
      "hcefg         286656\n",
      "csmcu         498657\n",
      "csmam              0\n",
      "flg_3dsmk          0\n",
      "label              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba9be8b6-10fb-4098-b37d-1769924af504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stscd        0      1\n",
      "0   0.0      746     53\n",
      "1   1.0    11959  10426\n",
      "2   2.0      132      0\n",
      "3   3.0        2      0\n",
      "4   4.0       13      0\n",
      "5    NA  8643645  21550\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## check stscd data distribution\n",
    "df = train_df.copy()\n",
    "df['stscd']=df['stscd'].cat.add_categories(\"NA\").fillna(\"NA\")\n",
    "stscd_table = df[['label','stscd']].pivot_table(index='stscd', columns='label', aggfunc=len, fill_value=0)\n",
    "stscd_table = stscd_table.reset_index().rename_axis(None, axis=1).rename_axis(None, axis=0)\n",
    "print(stscd_table)\n",
    "stscd_table.plot(kind='bar', stacked=False, figsize=(10, 6)).set_ylim(0, 30000) \n",
    "plt.xlabel('stscd Categories')\n",
    "plt.ylabel('label Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4d2a0f-7019-4e07-a77f-1ba70a5fdb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8665195\n",
       "0      23331\n",
       "Name: stscd_missing, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary indicator for missing values\n",
    "train_df['stscd_missing'] = train_df['stscd'].isnull().astype('int32')\n",
    "train_df['stscd_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ee4bd06-84c0-4eab-a368-36860944e0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txkey            0\n",
      "locdt            0\n",
      "loctm            0\n",
      "chid             0\n",
      "cano             0\n",
      "contp            0\n",
      "etymd            0\n",
      "mchno            0\n",
      "acqic            0\n",
      "mcc              0\n",
      "conam            0\n",
      "ecfg             0\n",
      "insfg            0\n",
      "iterm            0\n",
      "bnsfg            0\n",
      "flam1            0\n",
      "stocn            0\n",
      "scity            0\n",
      "stscd            0\n",
      "ovrlt            0\n",
      "flbmk            0\n",
      "hcefg            0\n",
      "csmcu            0\n",
      "csmam            0\n",
      "flg_3dsmk        0\n",
      "label            0\n",
      "stscd_missing    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'stscd', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"unknown\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    train_df[column] = train_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "# Check for missing values\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe267a7-2509-4785-90c3-0b66d87a6f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb6ae916-8db0-4a22-a8fa-404ed8bc1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txkey全部都是唯一資料，刪除不用\n",
    "train_df.drop('txkey', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "467af3c0-f434-427c-9f74-e972f64af759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label轉成數值，不轉會出現error\n",
    "train_df['label'] = train_df['label'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2cb0091-f5e4-4880-b182-ac349eb9fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cae7fd3-e41e-444e-84bf-f4d89265b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chid', 'cano', 'contp', 'etymd', 'mchno', 'acqic', 'mcc', 'ecfg', 'insfg', 'bnsfg', 'stocn', 'scity', 'stscd', 'ovrlt', 'flbmk', 'hcefg', 'csmcu', 'flg_3dsmk']\n",
      "Number of categorical feature: 18\n"
     ]
    }
   ],
   "source": [
    "categorical_feature = [col for col in train_df.columns if train_df[col].dtype == 'category' and col != 'label']\n",
    "print(categorical_feature)\n",
    "print('Number of categorical feature:', len(categorical_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24c1264-f61b-4db0-a83c-16fdb19c320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_40581_row10_col1, #T_40581_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_40581\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_40581_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_40581_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_40581_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_40581_row0_col1\" class=\"data row0 col1\" >6969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_40581_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_40581_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_40581_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_40581_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_40581_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_40581_row3_col1\" class=\"data row3 col1\" >(8688526, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_40581_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_40581_row4_col1\" class=\"data row4 col1\" >(14725654, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_40581_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_40581_row5_col1\" class=\"data row5 col1\" >(12119096, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_40581_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_40581_row6_col1\" class=\"data row6 col1\" >(2606558, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_40581_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_40581_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_40581_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_40581_row8_col1\" class=\"data row8 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_40581_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_40581_row9_col1\" class=\"data row9 col1\" >18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_40581_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_40581_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_40581_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_40581_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_40581_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_40581_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_40581_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_40581_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_40581_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_40581_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_40581_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_40581_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_40581_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_40581_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_40581_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_40581_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_40581_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_40581_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_40581_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_40581_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_40581_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_40581_row20_col1\" class=\"data row20 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_40581_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_40581_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_40581_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_40581_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_40581_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_40581_row23_col1\" class=\"data row23 col1\" >00_Exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40581_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_40581_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_40581_row24_col1\" class=\"data row24 col1\" >dea1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f564f513220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7f5698cce1a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=16,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='00_Exp',\n",
    "          session_id=6969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3796914-8158-451e-b050-4cb298205fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>xgboost.sklearn.XGBClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>catboost.core.CatBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "xgboost         Extreme Gradient Boosting   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "catboost              CatBoost Classifier   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "xgboost                       xgboost.sklearn.XGBClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "catboost                   catboost.core.CatBoostClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc297006-9f80-40c5-8cc6-214b94de6bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cb9a4 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cb9a4_row0_col0, #T_cb9a4_row0_col2, #T_cb9a4_row0_col3, #T_cb9a4_row1_col0, #T_cb9a4_row1_col1, #T_cb9a4_row1_col4, #T_cb9a4_row1_col5, #T_cb9a4_row1_col6, #T_cb9a4_row1_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cb9a4_row0_col1, #T_cb9a4_row0_col4, #T_cb9a4_row0_col5, #T_cb9a4_row0_col6, #T_cb9a4_row0_col7, #T_cb9a4_row1_col2, #T_cb9a4_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_cb9a4_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_cb9a4_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cb9a4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cb9a4_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_cb9a4_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_cb9a4_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_cb9a4_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_cb9a4_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_cb9a4_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_cb9a4_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_cb9a4_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_cb9a4_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cb9a4_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_cb9a4_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_cb9a4_row0_col1\" class=\"data row0 col1\" >0.9987</td>\n",
       "      <td id=\"T_cb9a4_row0_col2\" class=\"data row0 col2\" >0.8948</td>\n",
       "      <td id=\"T_cb9a4_row0_col3\" class=\"data row0 col3\" >0.6878</td>\n",
       "      <td id=\"T_cb9a4_row0_col4\" class=\"data row0 col4\" >0.9620</td>\n",
       "      <td id=\"T_cb9a4_row0_col5\" class=\"data row0 col5\" >0.8021</td>\n",
       "      <td id=\"T_cb9a4_row0_col6\" class=\"data row0 col6\" >0.8015</td>\n",
       "      <td id=\"T_cb9a4_row0_col7\" class=\"data row0 col7\" >0.8129</td>\n",
       "      <td id=\"T_cb9a4_row0_col8\" class=\"data row0 col8\" >174.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb9a4_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_cb9a4_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_cb9a4_row1_col1\" class=\"data row1 col1\" >0.9986</td>\n",
       "      <td id=\"T_cb9a4_row1_col2\" class=\"data row1 col2\" >0.9465</td>\n",
       "      <td id=\"T_cb9a4_row1_col3\" class=\"data row1 col3\" >0.7303</td>\n",
       "      <td id=\"T_cb9a4_row1_col4\" class=\"data row1 col4\" >0.8832</td>\n",
       "      <td id=\"T_cb9a4_row1_col5\" class=\"data row1 col5\" >0.7980</td>\n",
       "      <td id=\"T_cb9a4_row1_col6\" class=\"data row1 col6\" >0.7974</td>\n",
       "      <td id=\"T_cb9a4_row1_col7\" class=\"data row1 col7\" >0.8017</td>\n",
       "      <td id=\"T_cb9a4_row1_col8\" class=\"data row1 col8\" >136.3740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f05a660d150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare selected models\n",
    "include_models = ['rf', 'lightgbm'] \n",
    "best = exp.compare_models(include=include_models, sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e28a9afd-c4c5-4354-8300-edb0a9108a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam',\n",
       "                                              'stscd_missing'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer...\n",
       "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                         class_weight=None, criterion='gini',\n",
       "                                         max_depth=None, max_features='sqrt',\n",
       "                                         max_leaf_nodes=None, max_samples=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=100, n_jobs=30,\n",
       "                                         oob_score=False, random_state=6969,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " '00_Exp_model_pipeline.pkl')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(best, '00_Exp_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4390379c-4e46-43ca-bf8e-ca08f16f0259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "best = exp.load_model('00_Exp_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc977fbe-48dc-490d-9200-97faac980814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=FastMemory(location=/dev/shm/joblib),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;,\n",
       "                                             &#x27;flam1&#x27;, &#x27;csmam&#x27;,\n",
       "                                             &#x27;stscd_missing&#x27;],\n",
       "                                    transformer=SimpleImputer(add_indicator=False,\n",
       "                                                              copy=True,\n",
       "                                                              fill_value=None,\n",
       "                                                              keep_empty_features=False,\n",
       "                                                              missing_values=nan,\n",
       "                                                              strategy=&#x27;mean&#x27;,\n",
       "                                                              verbose=&#x27;deprecated&#x27;))),\n",
       "                (&#x27;cate...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion=&#x27;gini&#x27;,\n",
       "                                        max_depth=None, max_features=&#x27;sqrt&#x27;,\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=30,\n",
       "                                        oob_score=False, random_state=6969,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=FastMemory(location=/dev/shm/joblib),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;,\n",
       "                                             &#x27;flam1&#x27;, &#x27;csmam&#x27;,\n",
       "                                             &#x27;stscd_missing&#x27;],\n",
       "                                    transformer=SimpleImputer(add_indicator=False,\n",
       "                                                              copy=True,\n",
       "                                                              fill_value=None,\n",
       "                                                              keep_empty_features=False,\n",
       "                                                              missing_values=nan,\n",
       "                                                              strategy=&#x27;mean&#x27;,\n",
       "                                                              verbose=&#x27;deprecated&#x27;))),\n",
       "                (&#x27;cate...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion=&#x27;gini&#x27;,\n",
       "                                        max_depth=None, max_features=&#x27;sqrt&#x27;,\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=30,\n",
       "                                        oob_score=False, random_state=6969,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None,\n",
       "                   include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;, &#x27;flam1&#x27;,\n",
       "                            &#x27;csmam&#x27;, &#x27;stscd_missing&#x27;],\n",
       "                   transformer=SimpleImputer(add_indicator=False, copy=True,\n",
       "                                             fill_value=None,\n",
       "                                             keep_empty_features=False,\n",
       "                                             missing_values=nan,\n",
       "                                             strategy=&#x27;mean&#x27;,\n",
       "                                             verbose=&#x27;deprecated&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None,\n",
       "                   include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;,\n",
       "                            &#x27;mcc&#x27;, &#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                            &#x27;stscd&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;hcefg&#x27;, &#x27;csmcu&#x27;,\n",
       "                            &#x27;flg_3dsmk&#x27;],\n",
       "                   transformer=SimpleImputer(add_indicator=False, copy=True,\n",
       "                                             fill_value=None,\n",
       "                                             keep_empty_features=False,\n",
       "                                             missing_values=nan,\n",
       "                                             strategy=&#x27;most_frequent&#x27;,\n",
       "                                             verbose=&#x27;deprecated&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None,\n",
       "                   include=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;,\n",
       "                            &#x27;flg_3dsmk&#x27;],\n",
       "                   transformer=OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;,\n",
       "                                                    &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;,\n",
       "                                                    &#x27;flg_3dsmk&#x27;],\n",
       "                                              drop_invariant=False,\n",
       "                                              handle_missing=&#x27;return_nan&#x27;,\n",
       "                                              handle_unknown=&#x27;value&#x27;,\n",
       "                                              mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;insf...\n",
       "                                                       {&#x27;col&#x27;: &#x27;bnsfg&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;ovrlt&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;flbmk&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}],\n",
       "                                              return_df=True, verbose=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;flg_3dsmk&#x27;],\n",
       "               handle_missing=&#x27;return_nan&#x27;,\n",
       "               mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;insfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;bnsfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ovrlt&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flbmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;flg_3dsmk&#x27;],\n",
       "               handle_missing=&#x27;return_nan&#x27;,\n",
       "               mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;insfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;bnsfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ovrlt&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flbmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}])</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None, include=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "                   transformer=OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;,\n",
       "                                                   &#x27;hcefg&#x27;],\n",
       "                                             drop_invariant=False,\n",
       "                                             handle_missing=&#x27;return_nan&#x27;,\n",
       "                                             handle_unknown=&#x27;value&#x27;,\n",
       "                                             return_df=True, use_cat_names=True,\n",
       "                                             verbose=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">rest_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None,\n",
       "                   include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;stocn&#x27;,\n",
       "                            &#x27;scity&#x27;, &#x27;csmcu&#x27;],\n",
       "                   transformer=TargetEncoder(cols=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;mchno&#x27;,\n",
       "                                                   &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;stocn&#x27;,\n",
       "                                                   &#x27;scity&#x27;, &#x27;csmcu&#x27;],\n",
       "                                             drop_invariant=False,\n",
       "                                             handle_missing=&#x27;return_nan&#x27;,\n",
       "                                             handle_unknown=&#x27;value&#x27;,\n",
       "                                             hierarchy=None,\n",
       "                                             min_samples_leaf=20,\n",
       "                                             return_df=True, smoothing=10,\n",
       "                                             verbose=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder(cols=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                    &#x27;csmcu&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder(cols=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                    &#x27;csmcu&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">balance: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None, include=None,\n",
       "                   transformer=FixImbalancer(estimator=RandomOverSampler(random_state=6969,\n",
       "                                                                         sampling_strategy=&#x27;auto&#x27;,\n",
       "                                                                         shrinkage=None)))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: FixImbalancer</label><div class=\"sk-toggleable__content\"><pre>FixImbalancer(estimator=RandomOverSampler(random_state=6969))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=6969)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=6969)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=30, random_state=6969)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory=FastMemory(location=/dev/shm/joblib),\n",
       "         steps=[('numerical_imputer',\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                             'flam1', 'csmam',\n",
       "                                             'stscd_missing'],\n",
       "                                    transformer=SimpleImputer(add_indicator=False,\n",
       "                                                              copy=True,\n",
       "                                                              fill_value=None,\n",
       "                                                              keep_empty_features=False,\n",
       "                                                              missing_values=nan,\n",
       "                                                              strategy='mean',\n",
       "                                                              verbose='deprecated'))),\n",
       "                ('cate...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='sqrt',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=30,\n",
       "                                        oob_score=False, random_state=6969,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b9c85dc-706e-4c20-9e14-0b39ec0978d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>11:35:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   11:35:46\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .   Random Forest Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tune_best \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/classification/oop.py:1558\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[0;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1369\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_library\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_library\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tuner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tuner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtuner_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuner_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:2672\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[0;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[1;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.sample_without_replacement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2666\u001b[0m         pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_sample_without_replacement,\n\u001b[1;32m   2667\u001b[0m     ):\n\u001b[1;32m   2668\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[1;32m   2669\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.ParameterGrid.__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2670\u001b[0m             pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_ParameterGrid_getitem,\n\u001b[1;32m   2671\u001b[0m         ):\n\u001b[0;32m-> 2672\u001b[0m             \u001b[43mmodel_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2674\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "tune_best = exp.tune_model(best, optimize='F1',early_stopping=True)\n",
    "# 250G RAM overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd387735-0d79-4303-ae3e-998c8f2cbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc1742-e1e1-421f-b9a3-0e9705877d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_model(tune_best, '00_tuned_model_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9aba72-1a03-4950-be1c-e55fdf002bac",
   "metadata": {},
   "source": [
    "###lighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ac225cf-a842-4b7f-9d94-fdd2b939c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70d49_row10_col1, #T_70d49_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70d49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70d49_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_70d49_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_70d49_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_70d49_row0_col1\" class=\"data row0 col1\" >6969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_70d49_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_70d49_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_70d49_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_70d49_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_70d49_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_70d49_row3_col1\" class=\"data row3 col1\" >(8688526, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_70d49_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_70d49_row4_col1\" class=\"data row4 col1\" >(14725654, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_70d49_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_70d49_row5_col1\" class=\"data row5 col1\" >(12119096, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_70d49_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_70d49_row6_col1\" class=\"data row6 col1\" >(2606558, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_70d49_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_70d49_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_70d49_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_70d49_row8_col1\" class=\"data row8 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_70d49_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_70d49_row9_col1\" class=\"data row9 col1\" >18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_70d49_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_70d49_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_70d49_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_70d49_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_70d49_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_70d49_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_70d49_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_70d49_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_70d49_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_70d49_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_70d49_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_70d49_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_70d49_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_70d49_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_70d49_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_70d49_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_70d49_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_70d49_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_70d49_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_70d49_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_70d49_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_70d49_row20_col1\" class=\"data row20 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_70d49_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_70d49_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_70d49_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_70d49_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_70d49_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_70d49_row23_col1\" class=\"data row23 col1\" >00_Exp_lighGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70d49_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_70d49_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_70d49_row24_col1\" class=\"data row24 col1\" >e6ff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f55997a08b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7f57c07a7400>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=8,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='00_Exp_lighGBM',\n",
    "          session_id=6969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9542487-7aa7-42b5-b84d-4a9807f840c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6a9fa th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6a9fa_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6a9fa_row0_col1, #T_6a9fa_row0_col2, #T_6a9fa_row0_col3, #T_6a9fa_row0_col4, #T_6a9fa_row0_col5, #T_6a9fa_row0_col6, #T_6a9fa_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_6a9fa_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6a9fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6a9fa_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6a9fa_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6a9fa_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6a9fa_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6a9fa_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6a9fa_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6a9fa_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6a9fa_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_6a9fa_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6a9fa_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_6a9fa_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_6a9fa_row0_col1\" class=\"data row0 col1\" >0.9986</td>\n",
       "      <td id=\"T_6a9fa_row0_col2\" class=\"data row0 col2\" >0.9488</td>\n",
       "      <td id=\"T_6a9fa_row0_col3\" class=\"data row0 col3\" >0.7306</td>\n",
       "      <td id=\"T_6a9fa_row0_col4\" class=\"data row0 col4\" >0.8837</td>\n",
       "      <td id=\"T_6a9fa_row0_col5\" class=\"data row0 col5\" >0.7983</td>\n",
       "      <td id=\"T_6a9fa_row0_col6\" class=\"data row0 col6\" >0.7976</td>\n",
       "      <td id=\"T_6a9fa_row0_col7\" class=\"data row0 col7\" >0.8020</td>\n",
       "      <td id=\"T_6a9fa_row0_col8\" class=\"data row0 col8\" >40.3940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f56c8feda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LightGBM = exp.compare_models(include=['lightgbm'], sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "440de9eb-57de-4856-b411-1dfe5d19ee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam',\n",
       "                                              'stscd_missing'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer...\n",
       "                  LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, importance_type='split',\n",
       "                                 learning_rate=0.1, max_depth=-1,\n",
       "                                 min_child_samples=20, min_child_weight=0.001,\n",
       "                                 min_split_gain=0.0, n_estimators=100, n_jobs=8,\n",
       "                                 num_leaves=31, objective=None,\n",
       "                                 random_state=6969, reg_alpha=0.0,\n",
       "                                 reg_lambda=0.0, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '00_Exp_lightgbm_pipeline.pkl')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(LightGBM, '00_Exp_lightgbm_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7d907ad-e5c0-49dd-bbf6-61597f6da3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_305b7_row5_col0, #T_305b7_row5_col1, #T_305b7_row5_col2, #T_305b7_row5_col3, #T_305b7_row5_col4, #T_305b7_row5_col5, #T_305b7_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_305b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_305b7_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_305b7_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_305b7_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_305b7_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_305b7_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_305b7_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_305b7_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_305b7_row0_col0\" class=\"data row0 col0\" >0.9986</td>\n",
       "      <td id=\"T_305b7_row0_col1\" class=\"data row0 col1\" >0.9935</td>\n",
       "      <td id=\"T_305b7_row0_col2\" class=\"data row0 col2\" >0.7076</td>\n",
       "      <td id=\"T_305b7_row0_col3\" class=\"data row0 col3\" >0.9024</td>\n",
       "      <td id=\"T_305b7_row0_col4\" class=\"data row0 col4\" >0.7932</td>\n",
       "      <td id=\"T_305b7_row0_col5\" class=\"data row0 col5\" >0.7926</td>\n",
       "      <td id=\"T_305b7_row0_col6\" class=\"data row0 col6\" >0.7985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_305b7_row1_col0\" class=\"data row1 col0\" >0.9987</td>\n",
       "      <td id=\"T_305b7_row1_col1\" class=\"data row1 col1\" >0.9947</td>\n",
       "      <td id=\"T_305b7_row1_col2\" class=\"data row1 col2\" >0.7081</td>\n",
       "      <td id=\"T_305b7_row1_col3\" class=\"data row1 col3\" >0.9137</td>\n",
       "      <td id=\"T_305b7_row1_col4\" class=\"data row1 col4\" >0.7978</td>\n",
       "      <td id=\"T_305b7_row1_col5\" class=\"data row1 col5\" >0.7972</td>\n",
       "      <td id=\"T_305b7_row1_col6\" class=\"data row1 col6\" >0.8037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_305b7_row2_col0\" class=\"data row2 col0\" >0.9986</td>\n",
       "      <td id=\"T_305b7_row2_col1\" class=\"data row2 col1\" >0.9936</td>\n",
       "      <td id=\"T_305b7_row2_col2\" class=\"data row2 col2\" >0.6949</td>\n",
       "      <td id=\"T_305b7_row2_col3\" class=\"data row2 col3\" >0.9019</td>\n",
       "      <td id=\"T_305b7_row2_col4\" class=\"data row2 col4\" >0.7850</td>\n",
       "      <td id=\"T_305b7_row2_col5\" class=\"data row2 col5\" >0.7843</td>\n",
       "      <td id=\"T_305b7_row2_col6\" class=\"data row2 col6\" >0.7910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_305b7_row3_col0\" class=\"data row3 col0\" >0.9987</td>\n",
       "      <td id=\"T_305b7_row3_col1\" class=\"data row3 col1\" >0.9941</td>\n",
       "      <td id=\"T_305b7_row3_col2\" class=\"data row3 col2\" >0.7107</td>\n",
       "      <td id=\"T_305b7_row3_col3\" class=\"data row3 col3\" >0.9166</td>\n",
       "      <td id=\"T_305b7_row3_col4\" class=\"data row3 col4\" >0.8007</td>\n",
       "      <td id=\"T_305b7_row3_col5\" class=\"data row3 col5\" >0.8000</td>\n",
       "      <td id=\"T_305b7_row3_col6\" class=\"data row3 col6\" >0.8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_305b7_row4_col0\" class=\"data row4 col0\" >0.9991</td>\n",
       "      <td id=\"T_305b7_row4_col1\" class=\"data row4 col1\" >0.9975</td>\n",
       "      <td id=\"T_305b7_row4_col2\" class=\"data row4 col2\" >0.8483</td>\n",
       "      <td id=\"T_305b7_row4_col3\" class=\"data row4 col3\" >0.9144</td>\n",
       "      <td id=\"T_305b7_row4_col4\" class=\"data row4 col4\" >0.8801</td>\n",
       "      <td id=\"T_305b7_row4_col5\" class=\"data row4 col5\" >0.8797</td>\n",
       "      <td id=\"T_305b7_row4_col6\" class=\"data row4 col6\" >0.8803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_305b7_row5_col0\" class=\"data row5 col0\" >0.9988</td>\n",
       "      <td id=\"T_305b7_row5_col1\" class=\"data row5 col1\" >0.9947</td>\n",
       "      <td id=\"T_305b7_row5_col2\" class=\"data row5 col2\" >0.7339</td>\n",
       "      <td id=\"T_305b7_row5_col3\" class=\"data row5 col3\" >0.9098</td>\n",
       "      <td id=\"T_305b7_row5_col4\" class=\"data row5 col4\" >0.8114</td>\n",
       "      <td id=\"T_305b7_row5_col5\" class=\"data row5 col5\" >0.8108</td>\n",
       "      <td id=\"T_305b7_row5_col6\" class=\"data row5 col6\" >0.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_305b7_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_305b7_row6_col0\" class=\"data row6 col0\" >0.0002</td>\n",
       "      <td id=\"T_305b7_row6_col1\" class=\"data row6 col1\" >0.0015</td>\n",
       "      <td id=\"T_305b7_row6_col2\" class=\"data row6 col2\" >0.0575</td>\n",
       "      <td id=\"T_305b7_row6_col3\" class=\"data row6 col3\" >0.0063</td>\n",
       "      <td id=\"T_305b7_row6_col4\" class=\"data row6 col4\" >0.0348</td>\n",
       "      <td id=\"T_305b7_row6_col5\" class=\"data row6 col5\" >0.0349</td>\n",
       "      <td id=\"T_305b7_row6_col6\" class=\"data row6 col6\" >0.0326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f55997a2b30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.988719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.552418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.525646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.007922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2497\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.613764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.544831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.776477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.661295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2497\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.696036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.561687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.753596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.656031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.497459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2497\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.588146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.789179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2497\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.700201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.880716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.588909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2497\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.595487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.589819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.622759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.546528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.799441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.768134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.570984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.622400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.826126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.454261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2576\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 4847638, number of negative: 4847638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.514816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2512\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695276, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.603723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.434646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2575\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.700307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Number of positive: 4847639, number of negative: 4847639\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.035890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2496\n",
      "[LightGBM] [Info] Number of data points in the train set: 9695278, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n"
     ]
    }
   ],
   "source": [
    "tune_lightgbm = exp.tune_model(LightGBM, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e768a01c-25b0-414a-83a8-6496f62a20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam',\n",
       "                                              'stscd_missing'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer...\n",
       "                                 boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, feature_fraction=0.6,\n",
       "                                 importance_type='split', learning_rate=0.1,\n",
       "                                 max_depth=-1, min_child_samples=36,\n",
       "                                 min_child_weight=0.001, min_split_gain=0.2,\n",
       "                                 n_estimators=80, n_jobs=8, num_leaves=90,\n",
       "                                 objective=None, random_state=6969,\n",
       "                                 reg_alpha=0.3, reg_lambda=1, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '00_tune_lightgbm_pipeline.pkl')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(tune_lightgbm, '00_tune_lightgbm_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce4cbd-84d6-4b43-8d6c-399e5f6b95fd",
   "metadata": {},
   "source": [
    "## Prediction of public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c77f215-23c4-4ae5-9f22-9b35398a13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = pd.read_csv('public_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda5104c-b940-49d6-b146-210cecf5560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df[['txkey','chid','cano','contp','etymd','mchno','acqic','mcc','ecfg','insfg','bnsfg',\\\n",
    "          'stocn','scity','stscd','ovrlt','flbmk','hcefg','csmcu','flg_3dsmk']] = \\\n",
    "    public_df[['txkey','chid','cano','contp','etymd','mchno','acqic','mcc','ecfg','insfg','bnsfg','stocn',\\\n",
    "              'scity','stscd','ovrlt','flbmk','hcefg','csmcu','flg_3dsmk']].astype('category')\n",
    "\n",
    "public_df[public_df.select_dtypes(include='int64').columns] = \\\n",
    "    public_df[public_df.select_dtypes(include='int64').columns].astype('int32')\n",
    "\n",
    "public_df[public_df.select_dtypes(include='float64').columns] = \\\n",
    "    public_df[public_df.select_dtypes(include='float64').columns].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39514828-853a-4d30-bd3a-479b66a58c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary indicator for missing values\n",
    "public_df['stscd_missing'] = public_df['stscd'].isnull().astype(int)\n",
    "public_df['stscd_missing'].value_counts()\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'stscd', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"unknown\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    public_df[column] = public_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "ID_public = public_df.txkey\n",
    "public_df.drop('txkey', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431f560b-55fc-47a4-b325-dad8771f5c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8688526 entries, 0 to 8688525\n",
      "Data columns (total 26 columns):\n",
      " #   Column         Dtype   \n",
      "---  ------         -----   \n",
      " 0   locdt          int32   \n",
      " 1   loctm          int32   \n",
      " 2   chid           category\n",
      " 3   cano           category\n",
      " 4   contp          category\n",
      " 5   etymd          category\n",
      " 6   mchno          category\n",
      " 7   acqic          category\n",
      " 8   mcc            category\n",
      " 9   conam          float32 \n",
      " 10  ecfg           category\n",
      " 11  insfg          category\n",
      " 12  iterm          float32 \n",
      " 13  bnsfg          category\n",
      " 14  flam1          int32   \n",
      " 15  stocn          category\n",
      " 16  scity          category\n",
      " 17  stscd          category\n",
      " 18  ovrlt          category\n",
      " 19  flbmk          category\n",
      " 20  hcefg          category\n",
      " 21  csmcu          category\n",
      " 22  csmam          int32   \n",
      " 23  flg_3dsmk      category\n",
      " 24  label          int32   \n",
      " 25  stscd_missing  int32   \n",
      "dtypes: category(18), float32(2), int32(6)\n",
      "memory usage: 560.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600182 entries, 0 to 600181\n",
      "Data columns (total 25 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   locdt          600182 non-null  int32   \n",
      " 1   loctm          600182 non-null  int32   \n",
      " 2   chid           600182 non-null  category\n",
      " 3   cano           600182 non-null  category\n",
      " 4   contp          600182 non-null  category\n",
      " 5   etymd          600182 non-null  category\n",
      " 6   mchno          600182 non-null  category\n",
      " 7   acqic          600182 non-null  category\n",
      " 8   mcc            600182 non-null  category\n",
      " 9   conam          600182 non-null  float32 \n",
      " 10  ecfg           600182 non-null  category\n",
      " 11  insfg          600182 non-null  category\n",
      " 12  iterm          600182 non-null  float32 \n",
      " 13  bnsfg          600182 non-null  category\n",
      " 14  flam1          600182 non-null  int32   \n",
      " 15  stocn          600182 non-null  category\n",
      " 16  scity          600182 non-null  category\n",
      " 17  stscd          600182 non-null  category\n",
      " 18  ovrlt          600182 non-null  category\n",
      " 19  flbmk          600182 non-null  category\n",
      " 20  hcefg          600182 non-null  category\n",
      " 21  csmcu          600182 non-null  category\n",
      " 22  csmam          600182 non-null  int32   \n",
      " 23  flg_3dsmk      600182 non-null  category\n",
      " 24  stscd_missing  600182 non-null  int64   \n",
      "dtypes: category(18), float32(2), int32(4), int64(1)\n",
      "memory usage: 57.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "public_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d398409-84e8-4a87-81b4-fb9c457af754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=Memory(location=None),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;,\n",
       "                                             &#x27;flam1&#x27;, &#x27;csmam&#x27;,\n",
       "                                             &#x27;stscd_missing&#x27;],\n",
       "                                    transformer=SimpleImputer())),\n",
       "                (&#x27;categorical_imputer&#x27;,\n",
       "                 TransformerWrapper(include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;contp&#x27;, &#x27;etymd&#x27;,\n",
       "                                             &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;ecfg&#x27;,\n",
       "                                             &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                                             &#x27;stscd&#x27;, &#x27;ovrlt&#x27;, &#x27;fl...\n",
       "                                    transformer=TargetEncoder(handle_missing=&#x27;return_nan&#x27;))),\n",
       "                (&#x27;balance&#x27;,\n",
       "                 TransformerWrapper(transformer=FixImbalancer(estimator=RandomOverSampler(random_state=6970)))),\n",
       "                (&#x27;trained_model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=1.0, bagging_freq=4,\n",
       "                                feature_fraction=0.6, min_child_samples=36,\n",
       "                                min_split_gain=0.2, n_estimators=80, n_jobs=8,\n",
       "                                num_leaves=90, random_state=6969, reg_alpha=0.3,\n",
       "                                reg_lambda=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=Memory(location=None),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;,\n",
       "                                             &#x27;flam1&#x27;, &#x27;csmam&#x27;,\n",
       "                                             &#x27;stscd_missing&#x27;],\n",
       "                                    transformer=SimpleImputer())),\n",
       "                (&#x27;categorical_imputer&#x27;,\n",
       "                 TransformerWrapper(include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;contp&#x27;, &#x27;etymd&#x27;,\n",
       "                                             &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;ecfg&#x27;,\n",
       "                                             &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                                             &#x27;stscd&#x27;, &#x27;ovrlt&#x27;, &#x27;fl...\n",
       "                                    transformer=TargetEncoder(handle_missing=&#x27;return_nan&#x27;))),\n",
       "                (&#x27;balance&#x27;,\n",
       "                 TransformerWrapper(transformer=FixImbalancer(estimator=RandomOverSampler(random_state=6970)))),\n",
       "                (&#x27;trained_model&#x27;,\n",
       "                 LGBMClassifier(bagging_fraction=1.0, bagging_freq=4,\n",
       "                                feature_fraction=0.6, min_child_samples=36,\n",
       "                                min_split_gain=0.2, n_estimators=80, n_jobs=8,\n",
       "                                num_leaves=90, random_state=6969, reg_alpha=0.3,\n",
       "                                reg_lambda=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;locdt&#x27;, &#x27;loctm&#x27;, &#x27;conam&#x27;, &#x27;iterm&#x27;, &#x27;flam1&#x27;,\n",
       "                            &#x27;csmam&#x27;, &#x27;stscd_missing&#x27;],\n",
       "                   transformer=SimpleImputer())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;,\n",
       "                            &#x27;mcc&#x27;, &#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;stocn&#x27;, &#x27;scity&#x27;,\n",
       "                            &#x27;stscd&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;hcefg&#x27;, &#x27;csmcu&#x27;,\n",
       "                            &#x27;flg_3dsmk&#x27;],\n",
       "                   transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;,\n",
       "                            &#x27;flg_3dsmk&#x27;],\n",
       "                   transformer=OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;,\n",
       "                                                    &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;,\n",
       "                                                    &#x27;flg_3dsmk&#x27;],\n",
       "                                              handle_missing=&#x27;return_nan&#x27;,\n",
       "                                              mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;insfg&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;bnsfg&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;ovrlt&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;flbmk&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                                                       {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;,\n",
       "                                                        &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                                                        &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}]))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;flg_3dsmk&#x27;],\n",
       "               handle_missing=&#x27;return_nan&#x27;,\n",
       "               mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;insfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;bnsfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ovrlt&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flbmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(cols=[&#x27;ecfg&#x27;, &#x27;insfg&#x27;, &#x27;bnsfg&#x27;, &#x27;ovrlt&#x27;, &#x27;flbmk&#x27;, &#x27;flg_3dsmk&#x27;],\n",
       "               handle_missing=&#x27;return_nan&#x27;,\n",
       "               mapping=[{&#x27;col&#x27;: &#x27;ecfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;insfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;bnsfg&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ovrlt&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flbmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;flg_3dsmk&#x27;, &#x27;data_type&#x27;: dtype(&#x27;float64&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0.0    0\n",
       "1.0    1\n",
       "NaN   -1\n",
       "dtype: int64}])</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "                   transformer=OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;,\n",
       "                                                   &#x27;hcefg&#x27;],\n",
       "                                             handle_missing=&#x27;return_nan&#x27;,\n",
       "                                             use_cat_names=True))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(cols=[&#x27;contp&#x27;, &#x27;etymd&#x27;, &#x27;stscd&#x27;, &#x27;hcefg&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, use_cat_names=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">rest_encoding: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;chid&#x27;, &#x27;cano&#x27;, &#x27;mchno&#x27;, &#x27;acqic&#x27;, &#x27;mcc&#x27;, &#x27;stocn&#x27;,\n",
       "                            &#x27;scity&#x27;, &#x27;csmcu&#x27;],\n",
       "                   transformer=TargetEncoder(handle_missing=&#x27;return_nan&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder(handle_missing=&#x27;return_nan&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder(handle_missing=&#x27;return_nan&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">balance: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(transformer=FixImbalancer(estimator=RandomOverSampler(random_state=6970)))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: FixImbalancer</label><div class=\"sk-toggleable__content\"><pre>FixImbalancer(estimator=RandomOverSampler(random_state=6970))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=6970)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=6970)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6,\n",
       "               min_child_samples=36, min_split_gain=0.2, n_estimators=80,\n",
       "               n_jobs=8, num_leaves=90, random_state=6969, reg_alpha=0.3,\n",
       "               reg_lambda=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory=Memory(location=None),\n",
       "         steps=[('numerical_imputer',\n",
       "                 TransformerWrapper(include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                             'flam1', 'csmam',\n",
       "                                             'stscd_missing'],\n",
       "                                    transformer=SimpleImputer())),\n",
       "                ('categorical_imputer',\n",
       "                 TransformerWrapper(include=['chid', 'cano', 'contp', 'etymd',\n",
       "                                             'mchno', 'acqic', 'mcc', 'ecfg',\n",
       "                                             'insfg', 'bnsfg', 'stocn', 'scity',\n",
       "                                             'stscd', 'ovrlt', 'fl...\n",
       "                                    transformer=TargetEncoder(handle_missing='return_nan'))),\n",
       "                ('balance',\n",
       "                 TransformerWrapper(transformer=FixImbalancer(estimator=RandomOverSampler(random_state=6970)))),\n",
       "                ('trained_model',\n",
       "                 LGBMClassifier(bagging_fraction=1.0, bagging_freq=4,\n",
       "                                feature_fraction=0.6, min_child_samples=36,\n",
       "                                min_split_gain=0.2, n_estimators=80, n_jobs=8,\n",
       "                                num_leaves=90, random_state=6969, reg_alpha=0.3,\n",
       "                                reg_lambda=1))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()\n",
    "tune_lightgbm = exp.load_model('00_tune_lightgbm_pipeline')\n",
    "tune_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27a9d373-dd64-4d2e-968d-ad351ab5bf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerWrapper' object has no attribute 'target_name_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tune_lightgbm00_predict \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune_lightgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpublic_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/classification/oop.py:2813\u001b[0m, in \u001b[0;36mClassificationExperiment.predict_model\u001b[0;34m(self, estimator, data, probability_threshold, encoded_labels, raw_score, round, verbose)\u001b[0m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_model\u001b[39m(\n\u001b[1;32m   2742\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2743\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2749\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2750\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;124;03m    This function predicts ``Label`` and ``Score`` (probability of predicted\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;124;03m    class) using a trained model. When ``data`` is None, it predicts label and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \n\u001b[1;32m   2811\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoded_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:4954\u001b[0m, in \u001b[0;36m_SupervisedExperiment.predict_model\u001b[0;34m(self, estimator, data, probability_threshold, encoded_labels, raw_score, round, verbose, ml_usecase, preprocess)\u001b[0m\n\u001b[1;32m   4952\u001b[0m data \u001b[38;5;241m=\u001b[39m data[X_columns]  \u001b[38;5;66;03m# Ignore all columns but the originals\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess:\n\u001b[0;32m-> 4954\u001b[0m     X_test_ \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_step:\n\u001b[1;32m   4959\u001b[0m         pipeline\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;241m.\u001b[39mappend(final_step)\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/pipeline.py:286\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X, y, filter_train_only)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filter_train_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 286\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_memory_full_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_train_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_train_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variable_return(X, y)\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/pipeline.py:110\u001b[0m, in \u001b[0;36m_full_transform\u001b[0;34m(pipeline, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_full_transform\u001b[39m(pipeline: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, transformer \u001b[38;5;129;01min\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39m_iter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 110\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_memory_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/pipeline.py:79\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m signature(transformer\u001b[38;5;241m.\u001b[39mtransform)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m     78\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m---> 79\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m     82\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m], output[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/credit_ML/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py:234\u001b[0m, in \u001b[0;36mTransformerWrapper.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     X \u001b[38;5;241m=\u001b[39m to_df(X, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 234\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_series(y, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_name_\u001b[49m)\n\u001b[1;32m    236\u001b[0m     args \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    237\u001b[0m     transform_params \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mtransform)\u001b[38;5;241m.\u001b[39mparameters\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransformerWrapper' object has no attribute 'target_name_'"
     ]
    }
   ],
   "source": [
    "tune_lightgbm00_predict = exp.predict_model(tune_lightgbm, data=public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da6f3c-20f4-46c7-9c09-979db1144662",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b033fc3-57a4-4c53-bd39-6b2aa0a129a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4bd30_row10_col1, #T_4bd30_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4bd30\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4bd30_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_4bd30_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4bd30_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_4bd30_row0_col1\" class=\"data row0 col1\" >6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4bd30_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_4bd30_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4bd30_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_4bd30_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4bd30_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_4bd30_row3_col1\" class=\"data row3 col1\" >(8688526, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4bd30_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_4bd30_row4_col1\" class=\"data row4 col1\" >(14725654, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4bd30_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_4bd30_row5_col1\" class=\"data row5 col1\" >(12119096, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4bd30_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_4bd30_row6_col1\" class=\"data row6 col1\" >(2606558, 58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4bd30_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_4bd30_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4bd30_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_4bd30_row8_col1\" class=\"data row8 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4bd30_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_4bd30_row9_col1\" class=\"data row9 col1\" >18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4bd30_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_4bd30_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_4bd30_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_4bd30_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_4bd30_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_4bd30_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_4bd30_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_4bd30_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_4bd30_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_4bd30_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_4bd30_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_4bd30_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_4bd30_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_4bd30_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_4bd30_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_4bd30_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_4bd30_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_4bd30_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_4bd30_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_4bd30_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_4bd30_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_4bd30_row20_col1\" class=\"data row20 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_4bd30_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_4bd30_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_4bd30_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_4bd30_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_4bd30_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_4bd30_row23_col1\" class=\"data row23 col1\" >00_Exp_RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bd30_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_4bd30_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_4bd30_row24_col1\" class=\"data row24 col1\" >4cf2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f57365b8d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 16:16:53 INFO mlflow.tracking.fluent: Experiment with name '00_Exp_RF' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7f57c07a7400>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=16,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='00_Exp_RF',\n",
    "          session_id=6970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba624810-d9eb-4910-b636-323991a0d7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bcfc5 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bcfc5_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bcfc5_row0_col1, #T_bcfc5_row0_col2, #T_bcfc5_row0_col3, #T_bcfc5_row0_col4, #T_bcfc5_row0_col5, #T_bcfc5_row0_col6, #T_bcfc5_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_bcfc5_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bcfc5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bcfc5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bcfc5_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_bcfc5_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_bcfc5_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_bcfc5_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_bcfc5_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_bcfc5_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_bcfc5_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_bcfc5_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bcfc5_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_bcfc5_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_bcfc5_row0_col1\" class=\"data row0 col1\" >0.9987</td>\n",
       "      <td id=\"T_bcfc5_row0_col2\" class=\"data row0 col2\" >0.8779</td>\n",
       "      <td id=\"T_bcfc5_row0_col3\" class=\"data row0 col3\" >0.6859</td>\n",
       "      <td id=\"T_bcfc5_row0_col4\" class=\"data row0 col4\" >0.9621</td>\n",
       "      <td id=\"T_bcfc5_row0_col5\" class=\"data row0 col5\" >0.8008</td>\n",
       "      <td id=\"T_bcfc5_row0_col6\" class=\"data row0 col6\" >0.8002</td>\n",
       "      <td id=\"T_bcfc5_row0_col7\" class=\"data row0 col7\" >0.8118</td>\n",
       "      <td id=\"T_bcfc5_row0_col8\" class=\"data row0 col8\" >171.3260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f564e309750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF = exp.compare_models(include=['rf'], sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa199dc-4270-4922-9e5a-515f25e5fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>16:37:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   16:37:31\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .   Random Forest Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755363ca36194d469431e9571fd8cfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "tune_RF = exp.tune_model(RF, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4d7fd-a3fa-4a9a-8477-45267e3090c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa935b-bb06-47ac-ac53-399881eac442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
