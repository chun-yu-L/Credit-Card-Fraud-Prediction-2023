{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = pd.read_csv('D:Tbrain_31/dataset_1st/public_processed.csv')\n",
    "train_df = pd.read_csv('D:Tbrain_31/dataset_1st/training.csv')\n",
    "### 保留 txkey 欄位最後上傳用\n",
    "final_df = public_df[['txkey']]\n",
    "\n",
    "### 預測用資料集，訓練完模型在跑這行就好\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "public_df = public_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "public_df[['locdt', 'loctm', 'flam1', 'csmam']] = public_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "public_df[['conam', 'iterm']] = public_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    public_df[column] = public_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "public_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "public_df.drop('txkey', axis=1, inplace=True)\n",
    "\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "train_df = train_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "train_df[['locdt', 'loctm', 'flam1', 'csmam']] = train_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "train_df[['conam', 'iterm']] = train_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    train_df[column] = train_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "train_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "### 移除不必要的column\n",
    "\n",
    "## 檢查txkey是否只包含唯一值\n",
    "#uni_txkey = train_df['txkey'].value_counts().reset_index()\n",
    "#print(uni_txkey.loc[uni_txkey['count'] != 1])\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "train_df.drop('txkey', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label轉成數值，不轉會出現error\n",
    "train_df['label'] = train_df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chid', 'cano', 'contp', 'etymd', 'mchno', 'acqic', 'mcc', 'ecfg', 'insfg', 'bnsfg', 'stocn', 'scity', 'ovrlt', 'flbmk', 'hcefg', 'csmcu', 'flg_3dsmk']\n",
      "Number of categorical feature: 17\n"
     ]
    }
   ],
   "source": [
    "categorical_feature = [col for col in train_df.columns if train_df[col].dtype == 'category' and col != 'label']\n",
    "print(categorical_feature)\n",
    "print('Number of categorical feature:', len(categorical_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dfaa5_row10_col1, #T_dfaa5_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dfaa5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dfaa5_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_dfaa5_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dfaa5_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_dfaa5_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dfaa5_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_dfaa5_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dfaa5_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_dfaa5_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dfaa5_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_dfaa5_row3_col1\" class=\"data row3 col1\" >(8688526, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_dfaa5_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_dfaa5_row4_col1\" class=\"data row4 col1\" >(14725654, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_dfaa5_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_dfaa5_row5_col1\" class=\"data row5 col1\" >(12119096, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_dfaa5_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_dfaa5_row6_col1\" class=\"data row6 col1\" >(2606558, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_dfaa5_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_dfaa5_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_dfaa5_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_dfaa5_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_dfaa5_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_dfaa5_row9_col1\" class=\"data row9 col1\" >17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_dfaa5_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_dfaa5_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_dfaa5_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_dfaa5_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_dfaa5_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_dfaa5_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_dfaa5_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_dfaa5_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_dfaa5_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_dfaa5_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_dfaa5_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_dfaa5_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_dfaa5_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_dfaa5_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_dfaa5_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_dfaa5_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_dfaa5_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_dfaa5_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_dfaa5_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_dfaa5_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_dfaa5_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_dfaa5_row20_col1\" class=\"data row20 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_dfaa5_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_dfaa5_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_dfaa5_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_dfaa5_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_dfaa5_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_dfaa5_row23_col1\" class=\"data row23 col1\" >01_FirstExp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dfaa5_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_dfaa5_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_dfaa5_row24_col1\" class=\"data row24 col1\" >3e4c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x219ff7d1480>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '0'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "2023/11/13 17:00:13 INFO mlflow.tracking.fluent: Experiment with name '01_FirstExp' does not exist. Creating a new experiment.\n",
      "WARNING:root:Malformed experiment '0'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '0'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\0\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "2023/11/13 17:00:13 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x2189e057f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=10,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='01_FirstExp',\n",
    "          session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>xgboost.sklearn.XGBClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>catboost.core.CatBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "xgboost         Extreme Gradient Boosting   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "catboost              CatBoost Classifier   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "xgboost                       xgboost.sklearn.XGBClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "catboost                   catboost.core.CatBoostClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56bc9 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bc9_row0_col0, #T_56bc9_row0_col4, #T_56bc9_row1_col0, #T_56bc9_row1_col2, #T_56bc9_row1_col3, #T_56bc9_row1_col5, #T_56bc9_row1_col6, #T_56bc9_row1_col7, #T_56bc9_row2_col0, #T_56bc9_row2_col1, #T_56bc9_row2_col2, #T_56bc9_row2_col3, #T_56bc9_row2_col4, #T_56bc9_row2_col5, #T_56bc9_row2_col6, #T_56bc9_row2_col7, #T_56bc9_row3_col0, #T_56bc9_row3_col1, #T_56bc9_row3_col2, #T_56bc9_row3_col3, #T_56bc9_row3_col4, #T_56bc9_row3_col5, #T_56bc9_row3_col6, #T_56bc9_row3_col7, #T_56bc9_row4_col0, #T_56bc9_row4_col1, #T_56bc9_row4_col2, #T_56bc9_row4_col3, #T_56bc9_row4_col4, #T_56bc9_row4_col5, #T_56bc9_row4_col6, #T_56bc9_row4_col7, #T_56bc9_row5_col0, #T_56bc9_row5_col1, #T_56bc9_row5_col2, #T_56bc9_row5_col3, #T_56bc9_row5_col4, #T_56bc9_row5_col5, #T_56bc9_row5_col6, #T_56bc9_row5_col7, #T_56bc9_row6_col0, #T_56bc9_row6_col1, #T_56bc9_row6_col2, #T_56bc9_row6_col3, #T_56bc9_row6_col4, #T_56bc9_row6_col5, #T_56bc9_row6_col6, #T_56bc9_row6_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bc9_row0_col1, #T_56bc9_row0_col2, #T_56bc9_row0_col3, #T_56bc9_row0_col5, #T_56bc9_row0_col6, #T_56bc9_row0_col7, #T_56bc9_row1_col1, #T_56bc9_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_56bc9_row0_col8, #T_56bc9_row1_col8, #T_56bc9_row2_col8, #T_56bc9_row3_col8, #T_56bc9_row5_col8, #T_56bc9_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_56bc9_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56bc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56bc9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_56bc9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_56bc9_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_56bc9_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_56bc9_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_56bc9_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_56bc9_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_56bc9_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_56bc9_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_56bc9_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_56bc9_row0_col1\" class=\"data row0 col1\" >0.9987</td>\n",
       "      <td id=\"T_56bc9_row0_col2\" class=\"data row0 col2\" >0.9627</td>\n",
       "      <td id=\"T_56bc9_row0_col3\" class=\"data row0 col3\" >0.7514</td>\n",
       "      <td id=\"T_56bc9_row0_col4\" class=\"data row0 col4\" >0.8818</td>\n",
       "      <td id=\"T_56bc9_row0_col5\" class=\"data row0 col5\" >0.8092</td>\n",
       "      <td id=\"T_56bc9_row0_col6\" class=\"data row0 col6\" >0.8086</td>\n",
       "      <td id=\"T_56bc9_row0_col7\" class=\"data row0 col7\" >0.8123</td>\n",
       "      <td id=\"T_56bc9_row0_col8\" class=\"data row0 col8\" >44.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_56bc9_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_56bc9_row1_col1\" class=\"data row1 col1\" >0.9987</td>\n",
       "      <td id=\"T_56bc9_row1_col2\" class=\"data row1 col2\" >0.8763</td>\n",
       "      <td id=\"T_56bc9_row1_col3\" class=\"data row1 col3\" >0.6872</td>\n",
       "      <td id=\"T_56bc9_row1_col4\" class=\"data row1 col4\" >0.9608</td>\n",
       "      <td id=\"T_56bc9_row1_col5\" class=\"data row1 col5\" >0.8013</td>\n",
       "      <td id=\"T_56bc9_row1_col6\" class=\"data row1 col6\" >0.8006</td>\n",
       "      <td id=\"T_56bc9_row1_col7\" class=\"data row1 col7\" >0.8120</td>\n",
       "      <td id=\"T_56bc9_row1_col8\" class=\"data row1 col8\" >269.4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row2\" class=\"row_heading level0 row2\" >dt</th>\n",
       "      <td id=\"T_56bc9_row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_56bc9_row2_col1\" class=\"data row2 col1\" >0.9986</td>\n",
       "      <td id=\"T_56bc9_row2_col2\" class=\"data row2 col2\" >0.8407</td>\n",
       "      <td id=\"T_56bc9_row2_col3\" class=\"data row2 col3\" >0.6817</td>\n",
       "      <td id=\"T_56bc9_row2_col4\" class=\"data row2 col4\" >0.9082</td>\n",
       "      <td id=\"T_56bc9_row2_col5\" class=\"data row2 col5\" >0.7770</td>\n",
       "      <td id=\"T_56bc9_row2_col6\" class=\"data row2 col6\" >0.7763</td>\n",
       "      <td id=\"T_56bc9_row2_col7\" class=\"data row2 col7\" >0.7853</td>\n",
       "      <td id=\"T_56bc9_row2_col8\" class=\"data row2 col8\" >64.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row3\" class=\"row_heading level0 row3\" >mlp</th>\n",
       "      <td id=\"T_56bc9_row3_col0\" class=\"data row3 col0\" >MLP Classifier</td>\n",
       "      <td id=\"T_56bc9_row3_col1\" class=\"data row3 col1\" >0.9374</td>\n",
       "      <td id=\"T_56bc9_row3_col2\" class=\"data row3 col2\" >0.7014</td>\n",
       "      <td id=\"T_56bc9_row3_col3\" class=\"data row3 col3\" >0.3857</td>\n",
       "      <td id=\"T_56bc9_row3_col4\" class=\"data row3 col4\" >0.0582</td>\n",
       "      <td id=\"T_56bc9_row3_col5\" class=\"data row3 col5\" >0.0706</td>\n",
       "      <td id=\"T_56bc9_row3_col6\" class=\"data row3 col6\" >0.0652</td>\n",
       "      <td id=\"T_56bc9_row3_col7\" class=\"data row3 col7\" >0.1028</td>\n",
       "      <td id=\"T_56bc9_row3_col8\" class=\"data row3 col8\" >1054.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row4\" class=\"row_heading level0 row4\" >nb</th>\n",
       "      <td id=\"T_56bc9_row4_col0\" class=\"data row4 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_56bc9_row4_col1\" class=\"data row4 col1\" >0.9868</td>\n",
       "      <td id=\"T_56bc9_row4_col2\" class=\"data row4 col2\" >0.6596</td>\n",
       "      <td id=\"T_56bc9_row4_col3\" class=\"data row4 col3\" >0.0612</td>\n",
       "      <td id=\"T_56bc9_row4_col4\" class=\"data row4 col4\" >0.0226</td>\n",
       "      <td id=\"T_56bc9_row4_col5\" class=\"data row4 col5\" >0.0330</td>\n",
       "      <td id=\"T_56bc9_row4_col6\" class=\"data row4 col6\" >0.0277</td>\n",
       "      <td id=\"T_56bc9_row4_col7\" class=\"data row4 col7\" >0.0313</td>\n",
       "      <td id=\"T_56bc9_row4_col8\" class=\"data row4 col8\" >42.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_56bc9_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_56bc9_row5_col1\" class=\"data row5 col1\" >0.9034</td>\n",
       "      <td id=\"T_56bc9_row5_col2\" class=\"data row5 col2\" >0.6499</td>\n",
       "      <td id=\"T_56bc9_row5_col3\" class=\"data row5 col3\" >0.3114</td>\n",
       "      <td id=\"T_56bc9_row5_col4\" class=\"data row5 col4\" >0.0120</td>\n",
       "      <td id=\"T_56bc9_row5_col5\" class=\"data row5 col5\" >0.0232</td>\n",
       "      <td id=\"T_56bc9_row5_col6\" class=\"data row5 col6\" >0.0162</td>\n",
       "      <td id=\"T_56bc9_row5_col7\" class=\"data row5 col7\" >0.0448</td>\n",
       "      <td id=\"T_56bc9_row5_col8\" class=\"data row5 col8\" >55.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row6\" class=\"row_heading level0 row6\" >svm</th>\n",
       "      <td id=\"T_56bc9_row6_col0\" class=\"data row6 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_56bc9_row6_col1\" class=\"data row6 col1\" >0.4609</td>\n",
       "      <td id=\"T_56bc9_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_56bc9_row6_col3\" class=\"data row6 col3\" >0.6183</td>\n",
       "      <td id=\"T_56bc9_row6_col4\" class=\"data row6 col4\" >0.0050</td>\n",
       "      <td id=\"T_56bc9_row6_col5\" class=\"data row6 col5\" >0.0100</td>\n",
       "      <td id=\"T_56bc9_row6_col6\" class=\"data row6 col6\" >0.0027</td>\n",
       "      <td id=\"T_56bc9_row6_col7\" class=\"data row6 col7\" >0.0112</td>\n",
       "      <td id=\"T_56bc9_row6_col8\" class=\"data row6 col8\" >174.1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2189de8ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# compare selected models\n",
    "include_models = ['lr', 'nb', 'dt', 'svm', 'mlp', 'rf', 'lightgbm'] \n",
    "best = exp.compare_models(include=include_models, sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.evaluate_model(best)\n",
    "#exp.plot_model(best, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWra...\n",
       "                  LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, importance_type='split',\n",
       "                                 learning_rate=0.1, max_depth=-1,\n",
       "                                 min_child_samples=20, min_child_weight=0.001,\n",
       "                                 min_split_gain=0.0, n_estimators=100, n_jobs=10,\n",
       "                                 num_leaves=31, objective=None, random_state=123,\n",
       "                                 reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '01_first_model_pipeline.pkl')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(best, '01_first_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_583c4_row5_col0, #T_583c4_row5_col1, #T_583c4_row5_col2, #T_583c4_row5_col3, #T_583c4_row5_col4, #T_583c4_row5_col5, #T_583c4_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_583c4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_583c4_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_583c4_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_583c4_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_583c4_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_583c4_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_583c4_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_583c4_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_583c4_row0_col0\" class=\"data row0 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row0_col1\" class=\"data row0 col1\" >0.9900</td>\n",
       "      <td id=\"T_583c4_row0_col2\" class=\"data row0 col2\" >0.7058</td>\n",
       "      <td id=\"T_583c4_row0_col3\" class=\"data row0 col3\" >0.9434</td>\n",
       "      <td id=\"T_583c4_row0_col4\" class=\"data row0 col4\" >0.8075</td>\n",
       "      <td id=\"T_583c4_row0_col5\" class=\"data row0 col5\" >0.8069</td>\n",
       "      <td id=\"T_583c4_row0_col6\" class=\"data row0 col6\" >0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_583c4_row1_col0\" class=\"data row1 col0\" >0.9991</td>\n",
       "      <td id=\"T_583c4_row1_col1\" class=\"data row1 col1\" >0.9872</td>\n",
       "      <td id=\"T_583c4_row1_col2\" class=\"data row1 col2\" >0.8127</td>\n",
       "      <td id=\"T_583c4_row1_col3\" class=\"data row1 col3\" >0.9426</td>\n",
       "      <td id=\"T_583c4_row1_col4\" class=\"data row1 col4\" >0.8728</td>\n",
       "      <td id=\"T_583c4_row1_col5\" class=\"data row1 col5\" >0.8724</td>\n",
       "      <td id=\"T_583c4_row1_col6\" class=\"data row1 col6\" >0.8748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_583c4_row2_col0\" class=\"data row2 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row2_col1\" class=\"data row2 col1\" >0.9881</td>\n",
       "      <td id=\"T_583c4_row2_col2\" class=\"data row2 col2\" >0.7183</td>\n",
       "      <td id=\"T_583c4_row2_col3\" class=\"data row2 col3\" >0.9363</td>\n",
       "      <td id=\"T_583c4_row2_col4\" class=\"data row2 col4\" >0.8130</td>\n",
       "      <td id=\"T_583c4_row2_col5\" class=\"data row2 col5\" >0.8124</td>\n",
       "      <td id=\"T_583c4_row2_col6\" class=\"data row2 col6\" >0.8196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_583c4_row3_col0\" class=\"data row3 col0\" >0.9986</td>\n",
       "      <td id=\"T_583c4_row3_col1\" class=\"data row3 col1\" >0.9851</td>\n",
       "      <td id=\"T_583c4_row3_col2\" class=\"data row3 col2\" >0.6784</td>\n",
       "      <td id=\"T_583c4_row3_col3\" class=\"data row3 col3\" >0.9360</td>\n",
       "      <td id=\"T_583c4_row3_col4\" class=\"data row3 col4\" >0.7867</td>\n",
       "      <td id=\"T_583c4_row3_col5\" class=\"data row3 col5\" >0.7860</td>\n",
       "      <td id=\"T_583c4_row3_col6\" class=\"data row3 col6\" >0.7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_583c4_row4_col0\" class=\"data row4 col0\" >0.9987</td>\n",
       "      <td id=\"T_583c4_row4_col1\" class=\"data row4 col1\" >0.9910</td>\n",
       "      <td id=\"T_583c4_row4_col2\" class=\"data row4 col2\" >0.7014</td>\n",
       "      <td id=\"T_583c4_row4_col3\" class=\"data row4 col3\" >0.9413</td>\n",
       "      <td id=\"T_583c4_row4_col4\" class=\"data row4 col4\" >0.8038</td>\n",
       "      <td id=\"T_583c4_row4_col5\" class=\"data row4 col5\" >0.8032</td>\n",
       "      <td id=\"T_583c4_row4_col6\" class=\"data row4 col6\" >0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_583c4_row5_col0\" class=\"data row5 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row5_col1\" class=\"data row5 col1\" >0.9883</td>\n",
       "      <td id=\"T_583c4_row5_col2\" class=\"data row5 col2\" >0.7233</td>\n",
       "      <td id=\"T_583c4_row5_col3\" class=\"data row5 col3\" >0.9399</td>\n",
       "      <td id=\"T_583c4_row5_col4\" class=\"data row5 col4\" >0.8168</td>\n",
       "      <td id=\"T_583c4_row5_col5\" class=\"data row5 col5\" >0.8162</td>\n",
       "      <td id=\"T_583c4_row5_col6\" class=\"data row5 col6\" >0.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_583c4_row6_col0\" class=\"data row6 col0\" >0.0002</td>\n",
       "      <td id=\"T_583c4_row6_col1\" class=\"data row6 col1\" >0.0021</td>\n",
       "      <td id=\"T_583c4_row6_col2\" class=\"data row6 col2\" >0.0465</td>\n",
       "      <td id=\"T_583c4_row6_col3\" class=\"data row6 col3\" >0.0031</td>\n",
       "      <td id=\"T_583c4_row6_col4\" class=\"data row6 col4\" >0.0294</td>\n",
       "      <td id=\"T_583c4_row6_col5\" class=\"data row6 col5\" >0.0295</td>\n",
       "      <td id=\"T_583c4_row6_col6\" class=\"data row6 col6\" >0.0268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x219b79a93f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    }
   ],
   "source": [
    "tune_best = exp.tune_model(best, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type=&#x27;gbdt&#x27;,\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type=&#x27;split&#x27;, learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type=&#x27;gbdt&#x27;,\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type=&#x27;split&#x27;, learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWra...\n",
       "                                 boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, feature_fraction=0.5,\n",
       "                                 importance_type='split', learning_rate=0.4,\n",
       "                                 max_depth=-1, min_child_samples=6,\n",
       "                                 min_child_weight=0.001, min_split_gain=0.3,\n",
       "                                 n_estimators=20, n_jobs=10, num_leaves=150,\n",
       "                                 objective=None, random_state=123,\n",
       "                                 reg_alpha=0.005, reg_lambda=0.0005,\n",
       "                                 subsample=1.0, subsample_for_bin=200000,\n",
       "                                 subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '02_tuned_model_pipeline.pkl')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(tune_best, '02_tuned_model_pipeline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
