{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = pd.read_csv('D:Tbrain_31/dataset_1st/public_processed.csv')\n",
    "train_df = pd.read_csv('D:Tbrain_31/dataset_1st/training.csv')\n",
    "### 保留 txkey 欄位最後上傳用\n",
    "final_df = public_df[['txkey']]\n",
    "\n",
    "### 預測用資料集，訓練完模型在跑這行就好\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "public_df = public_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "public_df[['locdt', 'loctm', 'flam1', 'csmam']] = public_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "public_df[['conam', 'iterm']] = public_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    public_df[column] = public_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "public_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "public_df.drop('txkey', axis=1, inplace=True)\n",
    "\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "train_df = train_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "train_df[['locdt', 'loctm', 'flam1', 'csmam']] = train_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "train_df[['conam', 'iterm']] = train_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    train_df[column] = train_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "train_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "### 移除不必要的column\n",
    "\n",
    "## 檢查txkey是否只包含唯一值\n",
    "#uni_txkey = train_df['txkey'].value_counts().reset_index()\n",
    "#print(uni_txkey.loc[uni_txkey['count'] != 1])\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "train_df.drop('txkey', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label轉成數值，不轉會出現error\n",
    "train_df['label'] = train_df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chid', 'cano', 'contp', 'etymd', 'mchno', 'acqic', 'mcc', 'ecfg', 'insfg', 'bnsfg', 'stocn', 'scity', 'ovrlt', 'flbmk', 'hcefg', 'csmcu', 'flg_3dsmk']\n",
      "Number of categorical feature: 17\n"
     ]
    }
   ],
   "source": [
    "categorical_feature = [col for col in train_df.columns if train_df[col].dtype == 'category' and col != 'label']\n",
    "print(categorical_feature)\n",
    "print('Number of categorical feature:', len(categorical_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ed84d_row10_col1, #T_ed84d_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ed84d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ed84d_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ed84d_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ed84d_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_ed84d_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ed84d_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ed84d_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ed84d_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_ed84d_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ed84d_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_ed84d_row3_col1\" class=\"data row3 col1\" >(8688526, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ed84d_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_ed84d_row4_col1\" class=\"data row4 col1\" >(14725654, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ed84d_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_ed84d_row5_col1\" class=\"data row5 col1\" >(12119096, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ed84d_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_ed84d_row6_col1\" class=\"data row6 col1\" >(2606558, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ed84d_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_ed84d_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ed84d_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_ed84d_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ed84d_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_ed84d_row9_col1\" class=\"data row9 col1\" >17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ed84d_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ed84d_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ed84d_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_ed84d_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ed84d_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_ed84d_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ed84d_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_ed84d_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ed84d_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_ed84d_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ed84d_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_ed84d_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ed84d_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_ed84d_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ed84d_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_ed84d_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ed84d_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ed84d_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ed84d_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ed84d_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ed84d_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ed84d_row20_col1\" class=\"data row20 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ed84d_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ed84d_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ed84d_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ed84d_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ed84d_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ed84d_row23_col1\" class=\"data row23 col1\" >01_FirstExp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed84d_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_ed84d_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_ed84d_row24_col1\" class=\"data row24 col1\" >beb0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35991e4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/14 11:00:33 INFO mlflow.tracking.fluent: Experiment with name '01_FirstExp' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x1248d7400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=10,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='01_FirstExp',\n",
    "          session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>xgboost.sklearn.XGBClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>catboost.core.CatBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "xgboost         Extreme Gradient Boosting   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "catboost              CatBoost Classifier   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "xgboost                       xgboost.sklearn.XGBClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "catboost                   catboost.core.CatBoostClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56bc9 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bc9_row0_col0, #T_56bc9_row0_col4, #T_56bc9_row1_col0, #T_56bc9_row1_col2, #T_56bc9_row1_col3, #T_56bc9_row1_col5, #T_56bc9_row1_col6, #T_56bc9_row1_col7, #T_56bc9_row2_col0, #T_56bc9_row2_col1, #T_56bc9_row2_col2, #T_56bc9_row2_col3, #T_56bc9_row2_col4, #T_56bc9_row2_col5, #T_56bc9_row2_col6, #T_56bc9_row2_col7, #T_56bc9_row3_col0, #T_56bc9_row3_col1, #T_56bc9_row3_col2, #T_56bc9_row3_col3, #T_56bc9_row3_col4, #T_56bc9_row3_col5, #T_56bc9_row3_col6, #T_56bc9_row3_col7, #T_56bc9_row4_col0, #T_56bc9_row4_col1, #T_56bc9_row4_col2, #T_56bc9_row4_col3, #T_56bc9_row4_col4, #T_56bc9_row4_col5, #T_56bc9_row4_col6, #T_56bc9_row4_col7, #T_56bc9_row5_col0, #T_56bc9_row5_col1, #T_56bc9_row5_col2, #T_56bc9_row5_col3, #T_56bc9_row5_col4, #T_56bc9_row5_col5, #T_56bc9_row5_col6, #T_56bc9_row5_col7, #T_56bc9_row6_col0, #T_56bc9_row6_col1, #T_56bc9_row6_col2, #T_56bc9_row6_col3, #T_56bc9_row6_col4, #T_56bc9_row6_col5, #T_56bc9_row6_col6, #T_56bc9_row6_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bc9_row0_col1, #T_56bc9_row0_col2, #T_56bc9_row0_col3, #T_56bc9_row0_col5, #T_56bc9_row0_col6, #T_56bc9_row0_col7, #T_56bc9_row1_col1, #T_56bc9_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_56bc9_row0_col8, #T_56bc9_row1_col8, #T_56bc9_row2_col8, #T_56bc9_row3_col8, #T_56bc9_row5_col8, #T_56bc9_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_56bc9_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56bc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56bc9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_56bc9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_56bc9_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_56bc9_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_56bc9_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_56bc9_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_56bc9_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_56bc9_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_56bc9_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_56bc9_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_56bc9_row0_col1\" class=\"data row0 col1\" >0.9987</td>\n",
       "      <td id=\"T_56bc9_row0_col2\" class=\"data row0 col2\" >0.9627</td>\n",
       "      <td id=\"T_56bc9_row0_col3\" class=\"data row0 col3\" >0.7514</td>\n",
       "      <td id=\"T_56bc9_row0_col4\" class=\"data row0 col4\" >0.8818</td>\n",
       "      <td id=\"T_56bc9_row0_col5\" class=\"data row0 col5\" >0.8092</td>\n",
       "      <td id=\"T_56bc9_row0_col6\" class=\"data row0 col6\" >0.8086</td>\n",
       "      <td id=\"T_56bc9_row0_col7\" class=\"data row0 col7\" >0.8123</td>\n",
       "      <td id=\"T_56bc9_row0_col8\" class=\"data row0 col8\" >44.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_56bc9_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_56bc9_row1_col1\" class=\"data row1 col1\" >0.9987</td>\n",
       "      <td id=\"T_56bc9_row1_col2\" class=\"data row1 col2\" >0.8763</td>\n",
       "      <td id=\"T_56bc9_row1_col3\" class=\"data row1 col3\" >0.6872</td>\n",
       "      <td id=\"T_56bc9_row1_col4\" class=\"data row1 col4\" >0.9608</td>\n",
       "      <td id=\"T_56bc9_row1_col5\" class=\"data row1 col5\" >0.8013</td>\n",
       "      <td id=\"T_56bc9_row1_col6\" class=\"data row1 col6\" >0.8006</td>\n",
       "      <td id=\"T_56bc9_row1_col7\" class=\"data row1 col7\" >0.8120</td>\n",
       "      <td id=\"T_56bc9_row1_col8\" class=\"data row1 col8\" >269.4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row2\" class=\"row_heading level0 row2\" >dt</th>\n",
       "      <td id=\"T_56bc9_row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_56bc9_row2_col1\" class=\"data row2 col1\" >0.9986</td>\n",
       "      <td id=\"T_56bc9_row2_col2\" class=\"data row2 col2\" >0.8407</td>\n",
       "      <td id=\"T_56bc9_row2_col3\" class=\"data row2 col3\" >0.6817</td>\n",
       "      <td id=\"T_56bc9_row2_col4\" class=\"data row2 col4\" >0.9082</td>\n",
       "      <td id=\"T_56bc9_row2_col5\" class=\"data row2 col5\" >0.7770</td>\n",
       "      <td id=\"T_56bc9_row2_col6\" class=\"data row2 col6\" >0.7763</td>\n",
       "      <td id=\"T_56bc9_row2_col7\" class=\"data row2 col7\" >0.7853</td>\n",
       "      <td id=\"T_56bc9_row2_col8\" class=\"data row2 col8\" >64.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row3\" class=\"row_heading level0 row3\" >mlp</th>\n",
       "      <td id=\"T_56bc9_row3_col0\" class=\"data row3 col0\" >MLP Classifier</td>\n",
       "      <td id=\"T_56bc9_row3_col1\" class=\"data row3 col1\" >0.9374</td>\n",
       "      <td id=\"T_56bc9_row3_col2\" class=\"data row3 col2\" >0.7014</td>\n",
       "      <td id=\"T_56bc9_row3_col3\" class=\"data row3 col3\" >0.3857</td>\n",
       "      <td id=\"T_56bc9_row3_col4\" class=\"data row3 col4\" >0.0582</td>\n",
       "      <td id=\"T_56bc9_row3_col5\" class=\"data row3 col5\" >0.0706</td>\n",
       "      <td id=\"T_56bc9_row3_col6\" class=\"data row3 col6\" >0.0652</td>\n",
       "      <td id=\"T_56bc9_row3_col7\" class=\"data row3 col7\" >0.1028</td>\n",
       "      <td id=\"T_56bc9_row3_col8\" class=\"data row3 col8\" >1054.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row4\" class=\"row_heading level0 row4\" >nb</th>\n",
       "      <td id=\"T_56bc9_row4_col0\" class=\"data row4 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_56bc9_row4_col1\" class=\"data row4 col1\" >0.9868</td>\n",
       "      <td id=\"T_56bc9_row4_col2\" class=\"data row4 col2\" >0.6596</td>\n",
       "      <td id=\"T_56bc9_row4_col3\" class=\"data row4 col3\" >0.0612</td>\n",
       "      <td id=\"T_56bc9_row4_col4\" class=\"data row4 col4\" >0.0226</td>\n",
       "      <td id=\"T_56bc9_row4_col5\" class=\"data row4 col5\" >0.0330</td>\n",
       "      <td id=\"T_56bc9_row4_col6\" class=\"data row4 col6\" >0.0277</td>\n",
       "      <td id=\"T_56bc9_row4_col7\" class=\"data row4 col7\" >0.0313</td>\n",
       "      <td id=\"T_56bc9_row4_col8\" class=\"data row4 col8\" >42.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_56bc9_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_56bc9_row5_col1\" class=\"data row5 col1\" >0.9034</td>\n",
       "      <td id=\"T_56bc9_row5_col2\" class=\"data row5 col2\" >0.6499</td>\n",
       "      <td id=\"T_56bc9_row5_col3\" class=\"data row5 col3\" >0.3114</td>\n",
       "      <td id=\"T_56bc9_row5_col4\" class=\"data row5 col4\" >0.0120</td>\n",
       "      <td id=\"T_56bc9_row5_col5\" class=\"data row5 col5\" >0.0232</td>\n",
       "      <td id=\"T_56bc9_row5_col6\" class=\"data row5 col6\" >0.0162</td>\n",
       "      <td id=\"T_56bc9_row5_col7\" class=\"data row5 col7\" >0.0448</td>\n",
       "      <td id=\"T_56bc9_row5_col8\" class=\"data row5 col8\" >55.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bc9_level0_row6\" class=\"row_heading level0 row6\" >svm</th>\n",
       "      <td id=\"T_56bc9_row6_col0\" class=\"data row6 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_56bc9_row6_col1\" class=\"data row6 col1\" >0.4609</td>\n",
       "      <td id=\"T_56bc9_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_56bc9_row6_col3\" class=\"data row6 col3\" >0.6183</td>\n",
       "      <td id=\"T_56bc9_row6_col4\" class=\"data row6 col4\" >0.0050</td>\n",
       "      <td id=\"T_56bc9_row6_col5\" class=\"data row6 col5\" >0.0100</td>\n",
       "      <td id=\"T_56bc9_row6_col6\" class=\"data row6 col6\" >0.0027</td>\n",
       "      <td id=\"T_56bc9_row6_col7\" class=\"data row6 col7\" >0.0112</td>\n",
       "      <td id=\"T_56bc9_row6_col8\" class=\"data row6 col8\" >174.1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2189de8ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# compare selected models\n",
    "include_models = ['lr', 'nb', 'dt', 'svm', 'mlp', 'rf', 'lightgbm'] \n",
    "best = exp.compare_models(include=include_models, sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.evaluate_model(best)\n",
    "#exp.plot_model(best, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWra...\n",
       "                  LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, importance_type='split',\n",
       "                                 learning_rate=0.1, max_depth=-1,\n",
       "                                 min_child_samples=20, min_child_weight=0.001,\n",
       "                                 min_split_gain=0.0, n_estimators=100, n_jobs=10,\n",
       "                                 num_leaves=31, objective=None, random_state=123,\n",
       "                                 reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '01_first_model_pipeline.pkl')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(best, '01_first_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_583c4_row5_col0, #T_583c4_row5_col1, #T_583c4_row5_col2, #T_583c4_row5_col3, #T_583c4_row5_col4, #T_583c4_row5_col5, #T_583c4_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_583c4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_583c4_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_583c4_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_583c4_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_583c4_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_583c4_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_583c4_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_583c4_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_583c4_row0_col0\" class=\"data row0 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row0_col1\" class=\"data row0 col1\" >0.9900</td>\n",
       "      <td id=\"T_583c4_row0_col2\" class=\"data row0 col2\" >0.7058</td>\n",
       "      <td id=\"T_583c4_row0_col3\" class=\"data row0 col3\" >0.9434</td>\n",
       "      <td id=\"T_583c4_row0_col4\" class=\"data row0 col4\" >0.8075</td>\n",
       "      <td id=\"T_583c4_row0_col5\" class=\"data row0 col5\" >0.8069</td>\n",
       "      <td id=\"T_583c4_row0_col6\" class=\"data row0 col6\" >0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_583c4_row1_col0\" class=\"data row1 col0\" >0.9991</td>\n",
       "      <td id=\"T_583c4_row1_col1\" class=\"data row1 col1\" >0.9872</td>\n",
       "      <td id=\"T_583c4_row1_col2\" class=\"data row1 col2\" >0.8127</td>\n",
       "      <td id=\"T_583c4_row1_col3\" class=\"data row1 col3\" >0.9426</td>\n",
       "      <td id=\"T_583c4_row1_col4\" class=\"data row1 col4\" >0.8728</td>\n",
       "      <td id=\"T_583c4_row1_col5\" class=\"data row1 col5\" >0.8724</td>\n",
       "      <td id=\"T_583c4_row1_col6\" class=\"data row1 col6\" >0.8748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_583c4_row2_col0\" class=\"data row2 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row2_col1\" class=\"data row2 col1\" >0.9881</td>\n",
       "      <td id=\"T_583c4_row2_col2\" class=\"data row2 col2\" >0.7183</td>\n",
       "      <td id=\"T_583c4_row2_col3\" class=\"data row2 col3\" >0.9363</td>\n",
       "      <td id=\"T_583c4_row2_col4\" class=\"data row2 col4\" >0.8130</td>\n",
       "      <td id=\"T_583c4_row2_col5\" class=\"data row2 col5\" >0.8124</td>\n",
       "      <td id=\"T_583c4_row2_col6\" class=\"data row2 col6\" >0.8196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_583c4_row3_col0\" class=\"data row3 col0\" >0.9986</td>\n",
       "      <td id=\"T_583c4_row3_col1\" class=\"data row3 col1\" >0.9851</td>\n",
       "      <td id=\"T_583c4_row3_col2\" class=\"data row3 col2\" >0.6784</td>\n",
       "      <td id=\"T_583c4_row3_col3\" class=\"data row3 col3\" >0.9360</td>\n",
       "      <td id=\"T_583c4_row3_col4\" class=\"data row3 col4\" >0.7867</td>\n",
       "      <td id=\"T_583c4_row3_col5\" class=\"data row3 col5\" >0.7860</td>\n",
       "      <td id=\"T_583c4_row3_col6\" class=\"data row3 col6\" >0.7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_583c4_row4_col0\" class=\"data row4 col0\" >0.9987</td>\n",
       "      <td id=\"T_583c4_row4_col1\" class=\"data row4 col1\" >0.9910</td>\n",
       "      <td id=\"T_583c4_row4_col2\" class=\"data row4 col2\" >0.7014</td>\n",
       "      <td id=\"T_583c4_row4_col3\" class=\"data row4 col3\" >0.9413</td>\n",
       "      <td id=\"T_583c4_row4_col4\" class=\"data row4 col4\" >0.8038</td>\n",
       "      <td id=\"T_583c4_row4_col5\" class=\"data row4 col5\" >0.8032</td>\n",
       "      <td id=\"T_583c4_row4_col6\" class=\"data row4 col6\" >0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_583c4_row5_col0\" class=\"data row5 col0\" >0.9988</td>\n",
       "      <td id=\"T_583c4_row5_col1\" class=\"data row5 col1\" >0.9883</td>\n",
       "      <td id=\"T_583c4_row5_col2\" class=\"data row5 col2\" >0.7233</td>\n",
       "      <td id=\"T_583c4_row5_col3\" class=\"data row5 col3\" >0.9399</td>\n",
       "      <td id=\"T_583c4_row5_col4\" class=\"data row5 col4\" >0.8168</td>\n",
       "      <td id=\"T_583c4_row5_col5\" class=\"data row5 col5\" >0.8162</td>\n",
       "      <td id=\"T_583c4_row5_col6\" class=\"data row5 col6\" >0.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_583c4_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_583c4_row6_col0\" class=\"data row6 col0\" >0.0002</td>\n",
       "      <td id=\"T_583c4_row6_col1\" class=\"data row6 col1\" >0.0021</td>\n",
       "      <td id=\"T_583c4_row6_col2\" class=\"data row6 col2\" >0.0465</td>\n",
       "      <td id=\"T_583c4_row6_col3\" class=\"data row6 col3\" >0.0031</td>\n",
       "      <td id=\"T_583c4_row6_col4\" class=\"data row6 col4\" >0.0294</td>\n",
       "      <td id=\"T_583c4_row6_col5\" class=\"data row6 col5\" >0.0295</td>\n",
       "      <td id=\"T_583c4_row6_col6\" class=\"data row6 col6\" >0.0268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x219b79a93f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\vghuser\\Desktop\\Credit-Card-Fraud-Prediction-2023\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    }
   ],
   "source": [
    "tune_best = exp.tune_model(best, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type=&#x27;gbdt&#x27;,\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type=&#x27;split&#x27;, learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type=&#x27;gbdt&#x27;,\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type=&#x27;split&#x27;, learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',\n",
       "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "               importance_type='split', learning_rate=0.4, max_depth=-1,\n",
       "               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,\n",
       "               n_estimators=20, n_jobs=10, num_leaves=150, objective=None,\n",
       "               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['locdt', 'loctm', 'conam', 'iterm',\n",
       "                                              'flam1', 'csmam'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWra...\n",
       "                                 boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, feature_fraction=0.5,\n",
       "                                 importance_type='split', learning_rate=0.4,\n",
       "                                 max_depth=-1, min_child_samples=6,\n",
       "                                 min_child_weight=0.001, min_split_gain=0.3,\n",
       "                                 n_estimators=20, n_jobs=10, num_leaves=150,\n",
       "                                 objective=None, random_state=123,\n",
       "                                 reg_alpha=0.005, reg_lambda=0.0005,\n",
       "                                 subsample=1.0, subsample_for_bin=200000,\n",
       "                                 subsample_freq=0))],\n",
       "          verbose=False),\n",
       " '02_tuned_model_pipeline.pkl')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.save_model(tune_best, '02_tuned_model_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新增測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize model and make first predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b309_row10_col1, #T_3b309_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b309\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b309_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_3b309_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3b309_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_3b309_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3b309_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3b309_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3b309_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_3b309_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3b309_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_3b309_row3_col1\" class=\"data row3 col1\" >(8688526, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3b309_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_3b309_row4_col1\" class=\"data row4 col1\" >(14725654, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3b309_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_3b309_row5_col1\" class=\"data row5 col1\" >(12119096, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3b309_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_3b309_row6_col1\" class=\"data row6 col1\" >(2606558, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3b309_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_3b309_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3b309_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_3b309_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3b309_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_3b309_row9_col1\" class=\"data row9 col1\" >17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3b309_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_3b309_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3b309_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_3b309_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3b309_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_3b309_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3b309_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_3b309_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3b309_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_3b309_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3b309_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_3b309_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3b309_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_3b309_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3b309_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_3b309_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3b309_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3b309_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3b309_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3b309_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_3b309_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3b309_row20_col1\" class=\"data row20 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_3b309_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3b309_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_3b309_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3b309_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_3b309_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3b309_row23_col1\" class=\"data row23 col1\" >01_FirstExp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b309_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_3b309_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_3b309_row24_col1\" class=\"data row24 col1\" >81a7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15e3e86f820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "2023/11/14 16:21:20 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x15d25ad8cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "public_df = pd.read_csv('/Tbrain_31/dataset_1st/public_processed.csv')\n",
    "train_df = pd.read_csv('/Tbrain_31/dataset_1st/training.csv')\n",
    "### 保留 txkey 欄位最後上傳用\n",
    "final_df = public_df[['txkey']]\n",
    "\n",
    "### 預測用資料集，訓練完模型在跑這行就好\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "public_df = public_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "public_df[['locdt', 'loctm', 'flam1', 'csmam']] = public_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "public_df[['conam', 'iterm']] = public_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    public_df[column] = public_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "public_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "public_df.drop('txkey', axis=1, inplace=True)\n",
    "\n",
    "## 把資料轉成正確data type\n",
    "# 類別變數比較多，所以先把全部轉成類別\n",
    "train_df = train_df.astype('category')\n",
    "\n",
    "# 剩下轉回數值變數\n",
    "train_df[['locdt', 'loctm', 'flam1', 'csmam']] = train_df[['locdt', 'loctm', 'flam1', 'csmam']].astype('int64')\n",
    "train_df[['conam', 'iterm']] = train_df[['conam', 'iterm']].astype('float64')\n",
    "\n",
    "\n",
    "## 缺失值填充\n",
    "\n",
    "# 指定要填充的欄位\n",
    "columns_to_fill = ['etymd', 'mcc', 'stocn', 'scity', 'hcefg', 'csmcu']\n",
    "\n",
    "# 將 \"others\" 添加到類別中，如果已經存在，則忽略\n",
    "for column in columns_to_fill:\n",
    "    train_df[column] = train_df[column].cat.add_categories('-1').fillna('-1')\n",
    "\n",
    "\n",
    "# stscd(狀態碼)幾乎全部都是缺失值，也應該不是重要特徵，先就刪掉這欄\n",
    "train_df.drop('stscd', axis=1, inplace=True)\n",
    "\n",
    "### 移除不必要的column\n",
    "\n",
    "## 檢查txkey是否只包含唯一值\n",
    "#uni_txkey = train_df['txkey'].value_counts().reset_index()\n",
    "#print(uni_txkey.loc[uni_txkey['count'] != 1])\n",
    "\n",
    "# txkey全部都是唯一資料，刪除不用\n",
    "train_df.drop('txkey', axis=1, inplace=True)\n",
    "\n",
    "# label轉成數值，不轉會出現error\n",
    "train_df['label'] = train_df['label'].astype('int64')\n",
    "\n",
    "# import ClassificationExperiment and init the class\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()\n",
    "\n",
    "categorical_feature = [col for col in train_df.columns if train_df[col].dtype == 'category' and col != 'label']\n",
    "#print(categorical_feature)\n",
    "#print('Number of categorical feature:', len(categorical_feature))\n",
    "\n",
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=10,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='01_FirstExp',\n",
    "          session_id=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune_and_caliberate_model_for_the first_trail_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "tune_model = exp.load_model('02_tuned_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 275, in fit\n    fitted_estimator = self._memory_fit(\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 68, in _fit_one\n    transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\meta_estimators.py\", line 152, in fit\n    self.classifier_.fit(X, y, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 270, in fit\n    X, y, _ = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 246, in _fit\n    fitted_transformer = self._memory_fit(\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 68, in _fit_one\n    transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\preprocess\\transformers.py\", line 229, in fit\n    self.transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\category_encoders\\utils.py\", line 306, in fit\n    raise ValueError('X does not contain the columns listed in cols')\nValueError: X does not contain the columns listed in cols\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tune_model \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02_tuned_model_pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m best_threshold_model \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m exp\u001b[38;5;241m.\u001b[39msave_model(best_threshold_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m03_tuned_thresholdOptimize_pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\classification\\oop.py:2693\u001b[0m, in \u001b[0;36mClassificationExperiment.optimize_threshold\u001b[1;34m(self, estimator, optimize, return_data, plot_kwargs, **shgo_kwargs)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.random.RandomState\u001b[39m\u001b[38;5;124m\"\u001b[39m, FixedRandom):\n\u001b[1;32m-> 2693\u001b[0m     result \u001b[38;5;241m=\u001b[39m shgo(objective, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mshgo_kwargs)\n\u001b[0;32m   2695\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2696\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimization loop finished successfully. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2697\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mfun\u001b[38;5;241m*\u001b[39mdirection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2698\u001b[0m )\n\u001b[0;32m   2699\u001b[0m \u001b[38;5;28mprint\u001b[39m(message)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:426\u001b[0m, in \u001b[0;36mshgo\u001b[1;34m(func, bounds, args, constraints, n, iters, callback, minimizer_kwargs, options, sampling_method)\u001b[0m\n\u001b[0;32m    420\u001b[0m shc \u001b[38;5;241m=\u001b[39m SHGO(func, bounds, args\u001b[38;5;241m=\u001b[39margs, constraints\u001b[38;5;241m=\u001b[39mconstraints, n\u001b[38;5;241m=\u001b[39mn,\n\u001b[0;32m    421\u001b[0m            iters\u001b[38;5;241m=\u001b[39miters, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    422\u001b[0m            minimizer_kwargs\u001b[38;5;241m=\u001b[39mminimizer_kwargs,\n\u001b[0;32m    423\u001b[0m            options\u001b[38;5;241m=\u001b[39moptions, sampling_method\u001b[38;5;241m=\u001b[39msampling_method)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Run the algorithm, process results and test success\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[43mshc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shc\u001b[38;5;241m.\u001b[39mbreak_routine:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shc\u001b[38;5;241m.\u001b[39mdisp:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:751\u001b[0m, in \u001b[0;36mSHGO.construct_complex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;66;03m# Iterate complex, process minimisers\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopping_criteria()\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# Build minimiser pool\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# Final iteration only needed if pools weren't minimised every iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:894\u001b[0m, in \u001b[0;36mSHGO.iterate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 894\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;66;03m# Build minimizer pool\u001b[39;00m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminimize_every_iter:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:933\u001b[0m, in \u001b[0;36mSHGO.iterate_delaunay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate_delaunay\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    928\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    Build a complex of Delaunay triangulated points\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m    Note: called with ``self.iterate_complex()`` after class initiation\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampled_surface\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfty_cons_sampl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfty_cons_sampl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_sampled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:1264\u001b[0m, in \u001b[0;36mSHGO.sampled_surface\u001b[1;34m(self, infty_cons_sampl)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorted_samples()\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;66;03m# Find objective function references\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_sampled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_shgo.py:1382\u001b[0m, in \u001b[0;36mSHGO.fun_ref\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Breaks the g loop\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_f:\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfty_cons_sampl:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\scipy\\optimize\\_optimize.py:539\u001b[0m, in \u001b[0;36m_wrap_scalar_function.<locals>.function_wrapper\u001b[1;34m(x, *wrapper_args)\u001b[0m\n\u001b[0;32m    537\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# backwards-compatibility, also allow np.array([1.3]), np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\classification\\oop.py:2662\u001b[0m, in \u001b[0;36mClassificationExperiment.optimize_threshold.<locals>.objective\u001b[1;34m(x, *args)\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   2661\u001b[0m     probability_threshold \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 2662\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2665\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2668\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2669\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpull(pop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2670\u001b[0m         \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2679\u001b[0m         ]\n\u001b[0;32m   2680\u001b[0m     )\n\u001b[0;32m   2681\u001b[0m     model_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m probability_threshold\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1533\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit_time\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m-> 1533\u001b[0m model, model_fit_time, model_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model_with_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# end runtime\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m runtime_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1126\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[1;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1126\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpipeline_with_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1140\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 275, in fit\n    fitted_estimator = self._memory_fit(\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 68, in _fit_one\n    transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\meta_estimators.py\", line 152, in fit\n    self.classifier_.fit(X, y, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 270, in fit\n    X, y, _ = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 246, in _fit\n    fitted_transformer = self._memory_fit(\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pipeline.py\", line 68, in _fit_one\n    transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\preprocess\\transformers.py\", line 229, in fit\n    self.transformer.fit(*args, **fit_params)\n  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\category_encoders\\utils.py\", line 306, in fit\n    raise ValueError('X does not contain the columns listed in cols')\nValueError: X does not contain the columns listed in cols\n"
     ]
    }
   ],
   "source": [
    "tune_model = exp.load_model('02_tuned_model_pipeline')\n",
    "best_threshold_model = exp.optimize_threshold(tune_model, optimize='F1')\n",
    "exp.save_model(best_threshold_model, '03_tuned_thresholdOptimize_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_bst_threshold_model = exp.finalize_model(best_threshold_model)\n",
    "exp.save_model(finalize_bst_threshold_model, '04_finalized_bst_threshold_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_threshold_tuned_caliberate_model = exp.calibrate_model(best_threshold_model)\n",
    "exp.save_model(bst_threshold_tuned_caliberate_model, '05_all_optimize_func_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalize_bst_threshold_caliberated_model = exp.finalize_model(bst_threshold_tuned_caliberate_model)\n",
    "exp.save_model(finalize_bst_threshold_caliberated_model, '06_finalized_lgbm_threshold_caliberate_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML run trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4fbe_row10_col1, #T_d4fbe_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4fbe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4fbe_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d4fbe_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4fbe_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d4fbe_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4fbe_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d4fbe_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4fbe_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d4fbe_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4fbe_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d4fbe_row3_col1\" class=\"data row3 col1\" >(8688526, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4fbe_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d4fbe_row4_col1\" class=\"data row4 col1\" >(14725654, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d4fbe_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d4fbe_row5_col1\" class=\"data row5 col1\" >(12119096, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d4fbe_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d4fbe_row6_col1\" class=\"data row6 col1\" >(2606558, 51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d4fbe_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_d4fbe_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d4fbe_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d4fbe_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d4fbe_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_d4fbe_row9_col1\" class=\"data row9 col1\" >17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d4fbe_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d4fbe_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d4fbe_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d4fbe_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d4fbe_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d4fbe_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d4fbe_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d4fbe_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d4fbe_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_d4fbe_row14_col1\" class=\"data row14 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d4fbe_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
       "      <td id=\"T_d4fbe_row15_col1\" class=\"data row15 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d4fbe_row16_col0\" class=\"data row16 col0\" >Fix imbalance</td>\n",
       "      <td id=\"T_d4fbe_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d4fbe_row17_col0\" class=\"data row17 col0\" >Fix imbalance method</td>\n",
       "      <td id=\"T_d4fbe_row17_col1\" class=\"data row17 col1\" >RandomOverSampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d4fbe_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d4fbe_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d4fbe_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d4fbe_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d4fbe_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d4fbe_row20_col1\" class=\"data row20 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_d4fbe_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d4fbe_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_d4fbe_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d4fbe_row22_col1\" class=\"data row22 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_d4fbe_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d4fbe_row23_col1\" class=\"data row23 col1\" >02_automlExp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fbe_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_d4fbe_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
       "      <td id=\"T_d4fbe_row24_col1\" class=\"data row24 col1\" >1bb1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15e42fab640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "2023/11/14 16:55:53 INFO mlflow.tracking.fluent: Experiment with name '02_automlExp' does not exist. Creating a new experiment.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 271, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 405, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1109, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1102, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"C:\\Users\\vghuser\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 183, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'D:\\Tbrain_31\\PyCaret_trial\\mlruns\\1\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x15d25ad8cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(train_df, target='label',\n",
    "          fix_imbalance=True, fix_imbalance_method='RandomOverSampler',\n",
    "          n_jobs=10,\n",
    "          fold=5,\n",
    "          log_experiment=True, experiment_name='02_automlExp',\n",
    "          session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_lgbm_model = exp.load_model('02_tuned_model_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_295be_row5_col0, #T_295be_row5_col1, #T_295be_row5_col2, #T_295be_row5_col3, #T_295be_row5_col4, #T_295be_row5_col5, #T_295be_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_295be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_295be_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_295be_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_295be_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_295be_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_295be_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_295be_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_295be_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_295be_row0_col0\" class=\"data row0 col0\" >0.9988</td>\n",
       "      <td id=\"T_295be_row0_col1\" class=\"data row0 col1\" >0.9900</td>\n",
       "      <td id=\"T_295be_row0_col2\" class=\"data row0 col2\" >0.7058</td>\n",
       "      <td id=\"T_295be_row0_col3\" class=\"data row0 col3\" >0.9434</td>\n",
       "      <td id=\"T_295be_row0_col4\" class=\"data row0 col4\" >0.8075</td>\n",
       "      <td id=\"T_295be_row0_col5\" class=\"data row0 col5\" >0.8069</td>\n",
       "      <td id=\"T_295be_row0_col6\" class=\"data row0 col6\" >0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_295be_row1_col0\" class=\"data row1 col0\" >0.9991</td>\n",
       "      <td id=\"T_295be_row1_col1\" class=\"data row1 col1\" >0.9872</td>\n",
       "      <td id=\"T_295be_row1_col2\" class=\"data row1 col2\" >0.8127</td>\n",
       "      <td id=\"T_295be_row1_col3\" class=\"data row1 col3\" >0.9426</td>\n",
       "      <td id=\"T_295be_row1_col4\" class=\"data row1 col4\" >0.8728</td>\n",
       "      <td id=\"T_295be_row1_col5\" class=\"data row1 col5\" >0.8724</td>\n",
       "      <td id=\"T_295be_row1_col6\" class=\"data row1 col6\" >0.8748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_295be_row2_col0\" class=\"data row2 col0\" >0.9988</td>\n",
       "      <td id=\"T_295be_row2_col1\" class=\"data row2 col1\" >0.9881</td>\n",
       "      <td id=\"T_295be_row2_col2\" class=\"data row2 col2\" >0.7183</td>\n",
       "      <td id=\"T_295be_row2_col3\" class=\"data row2 col3\" >0.9363</td>\n",
       "      <td id=\"T_295be_row2_col4\" class=\"data row2 col4\" >0.8130</td>\n",
       "      <td id=\"T_295be_row2_col5\" class=\"data row2 col5\" >0.8124</td>\n",
       "      <td id=\"T_295be_row2_col6\" class=\"data row2 col6\" >0.8196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_295be_row3_col0\" class=\"data row3 col0\" >0.9986</td>\n",
       "      <td id=\"T_295be_row3_col1\" class=\"data row3 col1\" >0.9851</td>\n",
       "      <td id=\"T_295be_row3_col2\" class=\"data row3 col2\" >0.6784</td>\n",
       "      <td id=\"T_295be_row3_col3\" class=\"data row3 col3\" >0.9360</td>\n",
       "      <td id=\"T_295be_row3_col4\" class=\"data row3 col4\" >0.7867</td>\n",
       "      <td id=\"T_295be_row3_col5\" class=\"data row3 col5\" >0.7860</td>\n",
       "      <td id=\"T_295be_row3_col6\" class=\"data row3 col6\" >0.7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_295be_row4_col0\" class=\"data row4 col0\" >0.9987</td>\n",
       "      <td id=\"T_295be_row4_col1\" class=\"data row4 col1\" >0.9910</td>\n",
       "      <td id=\"T_295be_row4_col2\" class=\"data row4 col2\" >0.7014</td>\n",
       "      <td id=\"T_295be_row4_col3\" class=\"data row4 col3\" >0.9413</td>\n",
       "      <td id=\"T_295be_row4_col4\" class=\"data row4 col4\" >0.8038</td>\n",
       "      <td id=\"T_295be_row4_col5\" class=\"data row4 col5\" >0.8032</td>\n",
       "      <td id=\"T_295be_row4_col6\" class=\"data row4 col6\" >0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_295be_row5_col0\" class=\"data row5 col0\" >0.9988</td>\n",
       "      <td id=\"T_295be_row5_col1\" class=\"data row5 col1\" >0.9883</td>\n",
       "      <td id=\"T_295be_row5_col2\" class=\"data row5 col2\" >0.7233</td>\n",
       "      <td id=\"T_295be_row5_col3\" class=\"data row5 col3\" >0.9399</td>\n",
       "      <td id=\"T_295be_row5_col4\" class=\"data row5 col4\" >0.8168</td>\n",
       "      <td id=\"T_295be_row5_col5\" class=\"data row5 col5\" >0.8162</td>\n",
       "      <td id=\"T_295be_row5_col6\" class=\"data row5 col6\" >0.8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_295be_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_295be_row6_col0\" class=\"data row6 col0\" >0.0002</td>\n",
       "      <td id=\"T_295be_row6_col1\" class=\"data row6 col1\" >0.0021</td>\n",
       "      <td id=\"T_295be_row6_col2\" class=\"data row6 col2\" >0.0465</td>\n",
       "      <td id=\"T_295be_row6_col3\" class=\"data row6 col3\" >0.0031</td>\n",
       "      <td id=\"T_295be_row6_col4\" class=\"data row6 col4\" >0.0294</td>\n",
       "      <td id=\"T_295be_row6_col5\" class=\"data row6 col5\" >0.0295</td>\n",
       "      <td id=\"T_295be_row6_col6\" class=\"data row6 col6\" >0.0268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15e736662c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    }
   ],
   "source": [
    "### 因為之前load的模型(tune_lgbm_model: 02_tuned_model_pipeline)不讓我直接blend\n",
    "## 所以利用其儲存的超參數重新創建一個lightgbm模型\n",
    "\n",
    "# 定義 LightGBM 的超參數\n",
    "lgbm_params = {\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 3,\n",
    "    'feature_fraction': 0.5,\n",
    "    'learning_rate': 0.4,\n",
    "    'min_child_samples': 6,\n",
    "    'min_split_gain': 0.3,\n",
    "    'n_estimators': 20,\n",
    "    'n_jobs': 10,\n",
    "    'num_leaves': 150,\n",
    "    'random_state': 123,\n",
    "    'reg_alpha': 0.005,\n",
    "    'reg_lambda': 0.0005\n",
    "}\n",
    "\n",
    "# 創建 LightGBM 模型\n",
    "tune_lgbm_model = exp.create_model('lightgbm', **lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b8de4_row5_col0, #T_b8de4_row5_col1, #T_b8de4_row5_col2, #T_b8de4_row5_col3, #T_b8de4_row5_col4, #T_b8de4_row5_col5, #T_b8de4_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b8de4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b8de4_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_b8de4_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_b8de4_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b8de4_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_b8de4_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_b8de4_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_b8de4_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b8de4_row0_col0\" class=\"data row0 col0\" >0.9988</td>\n",
       "      <td id=\"T_b8de4_row0_col1\" class=\"data row0 col1\" >0.8749</td>\n",
       "      <td id=\"T_b8de4_row0_col2\" class=\"data row0 col2\" >0.6922</td>\n",
       "      <td id=\"T_b8de4_row0_col3\" class=\"data row0 col3\" >0.9625</td>\n",
       "      <td id=\"T_b8de4_row0_col4\" class=\"data row0 col4\" >0.8053</td>\n",
       "      <td id=\"T_b8de4_row0_col5\" class=\"data row0 col5\" >0.8047</td>\n",
       "      <td id=\"T_b8de4_row0_col6\" class=\"data row0 col6\" >0.8157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b8de4_row1_col0\" class=\"data row1 col0\" >0.9988</td>\n",
       "      <td id=\"T_b8de4_row1_col1\" class=\"data row1 col1\" >0.8806</td>\n",
       "      <td id=\"T_b8de4_row1_col2\" class=\"data row1 col2\" >0.6927</td>\n",
       "      <td id=\"T_b8de4_row1_col3\" class=\"data row1 col3\" >0.9589</td>\n",
       "      <td id=\"T_b8de4_row1_col4\" class=\"data row1 col4\" >0.8044</td>\n",
       "      <td id=\"T_b8de4_row1_col5\" class=\"data row1 col5\" >0.8037</td>\n",
       "      <td id=\"T_b8de4_row1_col6\" class=\"data row1 col6\" >0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b8de4_row2_col0\" class=\"data row2 col0\" >0.9987</td>\n",
       "      <td id=\"T_b8de4_row2_col1\" class=\"data row2 col1\" >0.8885</td>\n",
       "      <td id=\"T_b8de4_row2_col2\" class=\"data row2 col2\" >0.6844</td>\n",
       "      <td id=\"T_b8de4_row2_col3\" class=\"data row2 col3\" >0.9552</td>\n",
       "      <td id=\"T_b8de4_row2_col4\" class=\"data row2 col4\" >0.7975</td>\n",
       "      <td id=\"T_b8de4_row2_col5\" class=\"data row2 col5\" >0.7968</td>\n",
       "      <td id=\"T_b8de4_row2_col6\" class=\"data row2 col6\" >0.8080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b8de4_row3_col0\" class=\"data row3 col0\" >0.9987</td>\n",
       "      <td id=\"T_b8de4_row3_col1\" class=\"data row3 col1\" >0.8654</td>\n",
       "      <td id=\"T_b8de4_row3_col2\" class=\"data row3 col2\" >0.6740</td>\n",
       "      <td id=\"T_b8de4_row3_col3\" class=\"data row3 col3\" >0.9600</td>\n",
       "      <td id=\"T_b8de4_row3_col4\" class=\"data row3 col4\" >0.7919</td>\n",
       "      <td id=\"T_b8de4_row3_col5\" class=\"data row3 col5\" >0.7913</td>\n",
       "      <td id=\"T_b8de4_row3_col6\" class=\"data row3 col6\" >0.8038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b8de4_row4_col0\" class=\"data row4 col0\" >0.9988</td>\n",
       "      <td id=\"T_b8de4_row4_col1\" class=\"data row4 col1\" >0.8722</td>\n",
       "      <td id=\"T_b8de4_row4_col2\" class=\"data row4 col2\" >0.6927</td>\n",
       "      <td id=\"T_b8de4_row4_col3\" class=\"data row4 col3\" >0.9673</td>\n",
       "      <td id=\"T_b8de4_row4_col4\" class=\"data row4 col4\" >0.8073</td>\n",
       "      <td id=\"T_b8de4_row4_col5\" class=\"data row4 col5\" >0.8067</td>\n",
       "      <td id=\"T_b8de4_row4_col6\" class=\"data row4 col6\" >0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_b8de4_row5_col0\" class=\"data row5 col0\" >0.9987</td>\n",
       "      <td id=\"T_b8de4_row5_col1\" class=\"data row5 col1\" >0.8763</td>\n",
       "      <td id=\"T_b8de4_row5_col2\" class=\"data row5 col2\" >0.6872</td>\n",
       "      <td id=\"T_b8de4_row5_col3\" class=\"data row5 col3\" >0.9608</td>\n",
       "      <td id=\"T_b8de4_row5_col4\" class=\"data row5 col4\" >0.8013</td>\n",
       "      <td id=\"T_b8de4_row5_col5\" class=\"data row5 col5\" >0.8006</td>\n",
       "      <td id=\"T_b8de4_row5_col6\" class=\"data row5 col6\" >0.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8de4_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_b8de4_row6_col0\" class=\"data row6 col0\" >0.0000</td>\n",
       "      <td id=\"T_b8de4_row6_col1\" class=\"data row6 col1\" >0.0078</td>\n",
       "      <td id=\"T_b8de4_row6_col2\" class=\"data row6 col2\" >0.0073</td>\n",
       "      <td id=\"T_b8de4_row6_col3\" class=\"data row6 col3\" >0.0040</td>\n",
       "      <td id=\"T_b8de4_row6_col4\" class=\"data row6 col4\" >0.0057</td>\n",
       "      <td id=\"T_b8de4_row6_col5\" class=\"data row6 col5\" >0.0057</td>\n",
       "      <td id=\"T_b8de4_row6_col6\" class=\"data row6 col6\" >0.0053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15e2f4e9b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model = exp.create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e7a67_row5_col0, #T_e7a67_row5_col1, #T_e7a67_row5_col2, #T_e7a67_row5_col3, #T_e7a67_row5_col4, #T_e7a67_row5_col5, #T_e7a67_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e7a67\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e7a67_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_e7a67_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_e7a67_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_e7a67_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_e7a67_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_e7a67_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_e7a67_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e7a67_row0_col0\" class=\"data row0 col0\" >0.9976</td>\n",
       "      <td id=\"T_e7a67_row0_col1\" class=\"data row0 col1\" >0.8564</td>\n",
       "      <td id=\"T_e7a67_row0_col2\" class=\"data row0 col2\" >0.7141</td>\n",
       "      <td id=\"T_e7a67_row0_col3\" class=\"data row0 col3\" >0.6616</td>\n",
       "      <td id=\"T_e7a67_row0_col4\" class=\"data row0 col4\" >0.6868</td>\n",
       "      <td id=\"T_e7a67_row0_col5\" class=\"data row0 col5\" >0.6856</td>\n",
       "      <td id=\"T_e7a67_row0_col6\" class=\"data row0 col6\" >0.6861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e7a67_row1_col0\" class=\"data row1 col0\" >0.9973</td>\n",
       "      <td id=\"T_e7a67_row1_col1\" class=\"data row1 col1\" >0.8651</td>\n",
       "      <td id=\"T_e7a67_row1_col2\" class=\"data row1 col2\" >0.7322</td>\n",
       "      <td id=\"T_e7a67_row1_col3\" class=\"data row1 col3\" >0.6126</td>\n",
       "      <td id=\"T_e7a67_row1_col4\" class=\"data row1 col4\" >0.6671</td>\n",
       "      <td id=\"T_e7a67_row1_col5\" class=\"data row1 col5\" >0.6657</td>\n",
       "      <td id=\"T_e7a67_row1_col6\" class=\"data row1 col6\" >0.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e7a67_row2_col0\" class=\"data row2 col0\" >0.9971</td>\n",
       "      <td id=\"T_e7a67_row2_col1\" class=\"data row2 col1\" >0.8588</td>\n",
       "      <td id=\"T_e7a67_row2_col2\" class=\"data row2 col2\" >0.7197</td>\n",
       "      <td id=\"T_e7a67_row2_col3\" class=\"data row2 col3\" >0.5906</td>\n",
       "      <td id=\"T_e7a67_row2_col4\" class=\"data row2 col4\" >0.6488</td>\n",
       "      <td id=\"T_e7a67_row2_col5\" class=\"data row2 col5\" >0.6473</td>\n",
       "      <td id=\"T_e7a67_row2_col6\" class=\"data row2 col6\" >0.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e7a67_row3_col0\" class=\"data row3 col0\" >0.9973</td>\n",
       "      <td id=\"T_e7a67_row3_col1\" class=\"data row3 col1\" >0.8448</td>\n",
       "      <td id=\"T_e7a67_row3_col2\" class=\"data row3 col2\" >0.6909</td>\n",
       "      <td id=\"T_e7a67_row3_col3\" class=\"data row3 col3\" >0.6221</td>\n",
       "      <td id=\"T_e7a67_row3_col4\" class=\"data row3 col4\" >0.6547</td>\n",
       "      <td id=\"T_e7a67_row3_col5\" class=\"data row3 col5\" >0.6533</td>\n",
       "      <td id=\"T_e7a67_row3_col6\" class=\"data row3 col6\" >0.6543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e7a67_row4_col0\" class=\"data row4 col0\" >0.9975</td>\n",
       "      <td id=\"T_e7a67_row4_col1\" class=\"data row4 col1\" >0.8565</td>\n",
       "      <td id=\"T_e7a67_row4_col2\" class=\"data row4 col2\" >0.7141</td>\n",
       "      <td id=\"T_e7a67_row4_col3\" class=\"data row4 col3\" >0.6486</td>\n",
       "      <td id=\"T_e7a67_row4_col4\" class=\"data row4 col4\" >0.6798</td>\n",
       "      <td id=\"T_e7a67_row4_col5\" class=\"data row4 col5\" >0.6785</td>\n",
       "      <td id=\"T_e7a67_row4_col6\" class=\"data row4 col6\" >0.6793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_e7a67_row5_col0\" class=\"data row5 col0\" >0.9974</td>\n",
       "      <td id=\"T_e7a67_row5_col1\" class=\"data row5 col1\" >0.8563</td>\n",
       "      <td id=\"T_e7a67_row5_col2\" class=\"data row5 col2\" >0.7142</td>\n",
       "      <td id=\"T_e7a67_row5_col3\" class=\"data row5 col3\" >0.6271</td>\n",
       "      <td id=\"T_e7a67_row5_col4\" class=\"data row5 col4\" >0.6674</td>\n",
       "      <td id=\"T_e7a67_row5_col5\" class=\"data row5 col5\" >0.6661</td>\n",
       "      <td id=\"T_e7a67_row5_col6\" class=\"data row5 col6\" >0.6677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e7a67_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_e7a67_row6_col0\" class=\"data row6 col0\" >0.0002</td>\n",
       "      <td id=\"T_e7a67_row6_col1\" class=\"data row6 col1\" >0.0066</td>\n",
       "      <td id=\"T_e7a67_row6_col2\" class=\"data row6 col2\" >0.0134</td>\n",
       "      <td id=\"T_e7a67_row6_col3\" class=\"data row6 col3\" >0.0254</td>\n",
       "      <td id=\"T_e7a67_row6_col4\" class=\"data row6 col4\" >0.0144</td>\n",
       "      <td id=\"T_e7a67_row6_col5\" class=\"data row6 col5\" >0.0145</td>\n",
       "      <td id=\"T_e7a67_row6_col6\" class=\"data row6 col6\" >0.0138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15d0c8c2530>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    }
   ],
   "source": [
    "tune_rf_model = exp.tune_model(rf_model, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Estimator tune_lgbm_model does not have the required fit() method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m blend_rf_lgbm \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblend_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtune_lgbm_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtune_rf_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\classification\\oop.py:1803\u001b[0m, in \u001b[0;36mClassificationExperiment.blend_models\u001b[1;34m(self, estimator_list, fold, round, choose_better, optimize, method, weights, fit_kwargs, groups, probability_threshold, verbose, return_train_score)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblend_models\u001b[39m(\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1701\u001b[0m     estimator_list: \u001b[38;5;28mlist\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1712\u001b[0m     return_train_score: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1713\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;124;03m    This function trains a Soft Voting / Majority Rule classifier for select\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;124;03m    models passed in the ``estimator_list`` param. The output of this function\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1800\u001b[0m \n\u001b[0;32m   1801\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblend_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\credit_ML\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:3305\u001b[0m, in \u001b[0;36m_SupervisedExperiment.blend_models\u001b[1;34m(self, estimator_list, fold, round, choose_better, optimize, method, weights, fit_kwargs, groups, probability_threshold, verbose, return_train_score)\u001b[0m\n\u001b[0;32m   3303\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m estimator_list:\n\u001b[0;32m   3304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3306\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have the required fit() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3307\u001b[0m         )\n\u001b[0;32m   3308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ml_usecase \u001b[38;5;241m==\u001b[39m MLUsecase\u001b[38;5;241m.\u001b[39mCLASSIFICATION:\n\u001b[0;32m   3309\u001b[0m         \u001b[38;5;66;03m# checking method parameter with estimator list\u001b[39;00m\n\u001b[0;32m   3310\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Estimator tune_lgbm_model does not have the required fit() method."
     ]
    }
   ],
   "source": [
    "blend_rf_lgbm = exp.blend_models(['tune_lgbm_model', 'tune_rf_model'], optimize='F1', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_rf_lgbm = exp.stack_models(['tune_lgbm_model', 'tune_rf_model'], optimize='F1', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1_model_by_automl = exp.automl(optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_model(tune_rf_model, '11_tuned_rf_model')\n",
    "exp.save_model(blend_rf_lgbm, '12_blend_rf_lgbm_model')\n",
    "exp.save_model(stack_rf_lgbm, '13_stack_rf_lgbm_model')\n",
    "exp.save_model(best_f1_model_by_automl, '14_best_f1_model_by_automl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimize_threshold = exp.optimize_threshold(best_f1_model_by_automl, optimize='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimize_threshold_caliberated = exp.calibrate_model(best_optimize_threshold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_model(best_optimize_threshold, '15_best_optimize_threshold')\n",
    "exp.save_model(best_optimize_threshold_caliberated, '16_best_optimize_threshold_caliberated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_by_automl_optimize_threshold_finalize = exp.finalize_model(best_optimize_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_threshold_caliberate = exp.finalize_model(best_optimize_threshold_caliberated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_model(bst_by_automl_optimize_threshold_finalize, '16_bst_by_automl_optimize_threshold_finalize')\n",
    "exp.save_model(bst_threshold_caliberate, '17_bst_threshold_caliberate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
